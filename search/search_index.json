{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MLIR RL","text":"<p>A deep reinforcement learning system for loop nest optimization in MLIR.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Method 1: Using Docker</li> <li>Method 2: Without Docker</li> <li>Data</li> <li>Configuration</li> <li>Configuration Parameters</li> <li>Example Configuration</li> <li>Usage</li> <li>Training</li> <li>Evaluation</li> <li>Paper Results</li> <li>Authors</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Start by cloning the repo:</p> <pre><code>git clone https://github.com/mohph197/MLIR-RL-artifact.git\n</code></pre> <p>Before proceeding, follow the instructions in the Data section to download and extract the benchmark data files.</p>"},{"location":"#method-1-using-docker","title":"Method 1: Using Docker","text":"<p>Build and run the Docker container:</p> <pre><code>cd &lt;/path/to/MLIR-RL-artifact&gt;\ndocker build -t mlir-rl-artifact .\ndocker run -it mlir-rl-artifact\n</code></pre>"},{"location":"#method-2-without-docker","title":"Method 2: Without Docker","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Conda or Miniconda</li> </ul>"},{"location":"#steps","title":"Steps","text":"<ol> <li>Install system dependencies and Conda packages:</li> </ol> <p>Start by activating a Conda environment, and then install packages as follows:</p> <pre><code>conda install -y \\\n    python=3.11 \\\n    git=2.51.2 \\\n    unzip=6.0 \\\n    cmake=4.1.2 \\\n    ninja=1.13.1 \\\n    binutils=2.45 \\\n    c-compiler=1.11.0 \\\n    cxx-compiler=1.11.0 \\\n    clang=21.1.5 \\\n    clangxx=21.1.5 \\\n    llvm-openmp=21.1.5 \\\n    lld=21.1.5 \\\n    poetry=2.2.1 \\\n    -c conda-forge\n</code></pre> <ol> <li>Clone and build LLVM/MLIR:</li> </ol> <pre><code>git clone --branch release/19.x --depth 1 https://github.com/llvm/llvm-project.git\n\ncd &lt;path/to/llvm-project&gt;\npip install -r mlir/python/requirements.txt\ncmake -S llvm -B build -G Ninja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DLLVM_ENABLE_PROJECTS=mlir \\\n    -DLLVM_TARGETS_TO_BUILD=X86 \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++ \\\n    -DLLVM_ENABLE_LLD=ON \\\n    -DMLIR_ENABLE_BINDINGS_PYTHON=ON\ncmake --build build --target check-mlir -j\ncmake --build build --target check-mlir-python -j\n</code></pre> <ol> <li>Set environment variables:</li> </ol> <pre><code>export PATH=\"&lt;path/to/llvm-project&gt;/build/bin:$PATH\"\nexport PYTHONPATH=\"&lt;/path/to/llvm-project&gt;/build/tools/mlir/python_packages/mlir_core\"\nexport LLVM_BUILD_PATH=\"&lt;/path/to/llvm-project&gt;/build\"\nexport MLIR_SHARED_LIBS=\"&lt;/path/to/llvm-project&gt;/build/lib/libmlir_runner_utils.so,&lt;/path/to/llvm-project&gt;/build/lib/libmlir_c_runner_utils.so,$CONDA_PREFIX/lib/libomp.so\"\n</code></pre> <ol> <li>Build custom tools:</li> </ol> <pre><code>cd &lt;/path/to/MLIR-RL-artifact&gt;/tools\ncmake -S ast_dumper -B ast_dumper/build -G Ninja \\\n    -DMLIR_DIR=$LLVM_BUILD_PATH/lib/cmake/mlir \\\n    -DLLVM_EXTERNAL_LIT=$LLVM_BUILD_PATH/bin/llvm-lit \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++\ncmake --build ast_dumper/build -j\n\ncmake -S pre_vec -B pre_vec/build -G Ninja \\\n    -DMLIR_DIR=$LLVM_BUILD_PATH/lib/cmake/mlir \\\n    -DLLVM_EXTERNAL_LIT=$LLVM_BUILD_PATH/bin/llvm-lit \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++\ncmake --build pre_vec/build -j\n</code></pre> <ol> <li>Create <code>.env</code> file:</li> </ol> <pre><code>AST_DUMPER_BIN_PATH=\"&lt;/path/to/MLIR-RL-artifact&gt;/tools/ast_dumper/build/bin/AstDumper\"\nPRE_VEC_BIN_PATH=\"&lt;/path/to/MLIR-RL-artifact&gt;/tools/pre_vec/build/bin/PreVec\"\nMLIR_SHARED_LIBS=\"&lt;/path/to/llvm-project&gt;/build/lib/libmlir_runner_utils.so,&lt;/path/to/llvm-project&gt;/build/lib/libmlir_c_runner_utils.so,&lt;/path/to/conda-env&gt;/lib/libomp.so\"\nOMP_NUM_THREADS=12\n</code></pre> <p>The path to conda environment can be found by running <code>echo $CONDA_PREFIX</code>.</p> <ol> <li>Install Python dependencies:</li> </ol> <pre><code>cd &lt;/path/to/MLIR-RL-artifact&gt;\npoetry install\n</code></pre> <ol> <li>Enable Execution of Scripts:</li> </ol> <pre><code>chmod +x scripts/*.sh\n</code></pre>"},{"location":"#data","title":"Data","text":"<p>Download the benchmarks file from file link and place it in the <code>data/</code> directory.</p> <p>Extract the benchmark files:</p> <pre><code>cd data\nunzip code_files.zip\ncd ..\n</code></pre> <p>The <code>data/</code> directory contains execution time JSON files that specify baseline execution times (in nanoseconds) and determine which benchmarks to use:</p> <ul> <li><code>execution_times_train.json</code> - Training benchmark set</li> <li><code>execution_times_eval.json</code> - Evaluation benchmark set</li> <li><code>execution_times_eval_full.json</code> - Full models evaluation benchmarks</li> <li><code>execution_times_eval_nn.json</code> - Neural networks single operators evaluation benchmarks</li> <li><code>execution_times_eval_lqcd.json</code> - Lattice QCD evaluation benchmarks</li> </ul> <p>These files have the format:</p> <pre><code>{\n  \"benchmark_name\": baseline_execution_time_ns,\n  ...\n}\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":"<p>Configuration files are located in <code>config/</code> and control all aspects of training and evaluation. The system uses the config file specified by the <code>CONFIG_FILE_PATH</code> environment variable.</p>"},{"location":"#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"#model-architecture","title":"Model Architecture","text":"<ul> <li><code>max_num_stores_loads</code> (int): Maximum number of load/store operations in nested loops</li> <li><code>max_num_loops</code> (int): Maximum number of nested loops</li> <li><code>max_num_load_store_dim</code> (int): Maximum number of dimensions in load/store buffers</li> <li><code>num_tile_sizes</code> (int): Number of tile sizes to consider</li> <li><code>vect_size_limit</code> (int): Vectorization size limit to prevent excessive vectorization</li> </ul>"},{"location":"#action-space","title":"Action Space","text":"<ul> <li><code>order</code> (list[list[str]]): Enforced sequence of actions. Each inner list specifies allowed actions at that step:</li> <li>Action symbols: <code>I</code> (Interchange), <code>T</code> (Tiling), <code>TP</code> (TiledParallelization), <code>TF</code> (TiledFusion), <code>V</code> (Vectorization), <code>NT</code> (NoTransformation)</li> <li><code>!</code>: Special symbol meaning \"Allow everything, except these actions\", e.g. <code>[\"!\", \"I\", \"NT\"]</code> means \"Allow everything, except Interchange and NoTransformation\"</li> <li><code>interchange_mode</code> (\"enumerate\" | \"pointers\" | \"continuous\"): Method for sampling interchange actions</li> </ul>"},{"location":"#exploration","title":"Exploration","text":"<ul> <li><code>exploration</code> (list): List of exploration strategies - <code>[\"entropy\"]</code> or <code>[\"epsilon\"]</code> or both</li> <li><code>init_epsilon</code> (float): Initial epsilon value for epsilon-greedy exploration (decays over training)</li> </ul>"},{"location":"#normalization","title":"Normalization","text":"<ul> <li><code>normalize_bounds</code> (\"none\" | \"max\" | \"log\"): How to normalize loop bounds in the input</li> <li><code>normalize_adv</code> (\"none\" | \"standard\" | \"max-abs\"): Advantage normalization method for PPO</li> </ul>"},{"location":"#experience-replay","title":"Experience Replay","text":"<ul> <li><code>reuse_experience</code> (\"none\" | \"random\" | \"topk\"): Experience replay strategy</li> <li><code>replay_count</code> (int): Number of trajectories to keep in replay buffer</li> </ul>"},{"location":"#training-hyperparameters","title":"Training Hyperparameters","text":"<ul> <li><code>bench_count</code> (int): Number of collected benchmarks per training iteration</li> <li><code>nb_iterations</code> (int): Total number of training iterations</li> <li><code>ppo_epochs</code> (int): Number of PPO update epochs per iteration</li> <li><code>ppo_batch_size</code> (int): Batch size for PPO updates</li> <li><code>value_epochs</code> (int): Number of value function update epochs (0 to update with policy)</li> <li><code>value_batch_size</code> (int): Batch size for value function updates</li> <li><code>value_coef</code> (float): Value loss coefficient in combined loss</li> <li><code>value_clip</code> (bool): Whether to clip value function loss</li> <li><code>entropy_coef</code> (float): Entropy bonus coefficient for exploration</li> <li><code>lr</code> (float): Learning rate for Adam optimizer</li> <li><code>truncate</code> (int): Maximum number of transformation steps per operation</li> </ul>"},{"location":"#data-sources","title":"Data Sources","text":"<ul> <li><code>benchmarks_folder_path</code> (str): Path to directory containing <code>.mlir</code> benchmark files</li> <li><code>json_file</code> (str): Path to training execution times JSON file</li> <li><code>eval_json_file</code> (str): Path to evaluation execution times JSON file</li> </ul>"},{"location":"#logging","title":"Logging","text":"<ul> <li><code>results_dir</code> (str): Directory where results will be saved</li> <li><code>tags</code> (list[str]): Optional tags for experiment tracking</li> <li><code>debug</code> (bool): Enable debug mode</li> <li><code>main_exec_data_file</code> (str): Path to global execution cache file (optional)</li> </ul>"},{"location":"#example-configuration","title":"Example Configuration","text":"<pre><code>{\n  \"max_num_stores_loads\": 7,\n  \"max_num_loops\": 12,\n  \"max_num_load_store_dim\": 12,\n  \"num_tile_sizes\": 7,\n  \"vect_size_limit\": 512,\n  \"order\": [[\"I\"], [\"!\", \"I\", \"NT\"], [\"!\", \"I\"], [\"V\", \"NT\"]],\n  \"interchange_mode\": \"pointers\",\n  \"exploration\": [\"entropy\"],\n  \"init_epsilon\": 0.0,\n  \"normalize_bounds\": \"max\",\n  \"normalize_adv\": \"standard\",\n  \"reuse_experience\": \"none\",\n  \"benchmarks_folder_path\": \"data/code_files\",\n  \"bench_count\": 64,\n  \"replay_count\": 0,\n  \"nb_iterations\": 20000,\n  \"ppo_epochs\": 4,\n  \"ppo_batch_size\": 64,\n  \"value_epochs\": 0,\n  \"value_batch_size\": 0,\n  \"value_coef\": 0.5,\n  \"value_clip\": false,\n  \"entropy_coef\": 0.01,\n  \"lr\": 0.001,\n  \"truncate\": 5,\n  \"json_file\": \"data/execution_times_train.json\",\n  \"eval_json_file\": \"data/execution_times_eval.json\",\n  \"tags\": [],\n  \"debug\": false,\n  \"main_exec_data_file\": \"\",\n  \"results_dir\": \"results\"\n}\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#training","title":"Training","text":"<p>Train the RL model:</p> <pre><code>./scripts/train.sh\n</code></pre> <p>Results will be saved to <code>results/run_&lt;id&gt;/</code>:</p> <ul> <li>Model snapshots: <code>results/run_&lt;id&gt;/models/</code> - Model checkpoints saved every 5 iterations</li> <li>Logs: <code>results/run_&lt;id&gt;/log/</code> - Training metrics including speedups, losses, rewards, and entropy values</li> </ul>"},{"location":"#evaluation","title":"Evaluation","text":"<p>Evaluate saved models:</p> <pre><code>./scripts/evaluate.sh\n</code></pre> <p>This command will evaluate all saved models in the <code>models/</code> directory.</p> <p>Results will be saved to <code>results/run_&lt;id&gt;/</code>:</p> <ul> <li>Evaluation logs: <code>results/run_&lt;id&gt;/log/</code> - Speedup metrics for each evaluated model</li> </ul>"},{"location":"#paper-results","title":"Paper Results","text":"<p>Evaluate the latest model in the <code>models/</code> directory on the evaluation benchmarks from the paper:</p> <pre><code>./scripts/paper.sh\n</code></pre> <p>Results will be saved to <code>paper/results/</code> as a JSON file in the format:</p> <pre><code>{\n  \"benchmark_name_1\": speedup_value,\n  \"benchmark_name_2\": speedup_value,\n  ...\n}\n</code></pre>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Mohammed Tirichine (km_tirichine@esi.dz)</li> <li>Nassim Ameur (kn_ameur@esi.dz)</li> <li>Iheb Nassim Aouadj (nassimiheb.aouadj@gmail.com)</li> <li>Nazim Bendib (jn_bendib@esi.dz)</li> <li>Bouchama Djad (bouchamadjad@gmail.com)</li> <li>Rafik Bouloudene (rafikobouloudene@gmail.com)</li> <li>Riyadh Baghdadi (baghdadi@nyu.edu)</li> </ul>"},{"location":"api_reference/benchmarks/","title":"Benchmarks","text":"<p>Benchmark loading and management module.</p> <p>This module provides functionality for loading benchmark data and extracting features from benchmark code. It handles loading MLIR benchmark files, extracting operation features, and optionally applying img2col transformations for convolutional operations.</p>"},{"location":"api_reference/benchmarks/#mlir_rl_artifact.benchmarks.Benchmarks","title":"<code>Benchmarks(is_training=True)</code>","text":"<p>A class that holds benchmarks data</p> <p>Parameters:</p> Name Type Description Default <code>is_training</code> <code>bool</code> <p>Whether to load train or evaluation set</p> <code>True</code> Source code in <code>mlir_rl_artifact/benchmarks.py</code> <pre><code>def __init__(self, is_training: bool = True):\n    \"\"\"Load benchmarks\n\n    Args:\n        is_training (bool): Whether to load train or evaluation set\n    \"\"\"\n    cfg = Config()\n    # Load benchmark names and execution times from json file\n    bench_json_file = cfg.json_file\n\n    # If we are in evaluation mode, use the evaluation json file if provided\n    if cfg.eval_json_file and not is_training:\n        bench_json_file = cfg.eval_json_file\n\n    with open(bench_json_file) as file:\n        benchmarks_json: dict[str, int] = json.load(file)\n\n    # Build benchmark features\n    self.data = []\n    for bench_name, root_exec_time in tqdm(benchmarks_json.items(), desc=\"Extracting benchmark features\", unit=\"bench\"):\n        bench_file = os.path.join(cfg.benchmarks_folder_path, bench_name + \".mlir\")\n        benchmark_data = extract_bench_features_from_file(bench_name, bench_file, root_exec_time)\n        # NOTE: For now img2col is applied to single operator codes only\n        if os.getenv(\"DISABLE_IMG2COL\", \"0\") != \"1\" and bench_name.startswith(\"conv_2d_\"):\n            modified = False\n            with Context():\n                bench_module = Module.parse(benchmark_data.code)\n            for op_tag in benchmark_data.operation_tags:\n                if 'conv_2d' not in benchmark_data.operations[op_tag].operation_name:\n                    continue\n                try:\n                    transform_img2col(bench_module, op_tag)\n                except Exception:\n                    print_alert(f\"Failed to apply img2col on {bench_name}[{op_tag}]\")\n                else:\n                    modified = True\n            if modified:\n                benchmark_data = extract_bench_features_from_code(bench_name, str(bench_module), root_exec_time)\n        self.data.append(benchmark_data)\n</code></pre>"},{"location":"api_reference/benchmarks/#mlir_rl_artifact.benchmarks.Benchmarks.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Get a benchmark by index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the benchmark to retrieve.</p> required <p>Returns:</p> Name Type Description <code>BenchmarkFeatures</code> <code>BenchmarkFeatures</code> <p>The benchmark features at the specified index.</p> Source code in <code>mlir_rl_artifact/benchmarks.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; BenchmarkFeatures:\n    \"\"\"Get a benchmark by index.\n\n    Args:\n        idx (int): The index of the benchmark to retrieve.\n\n    Returns:\n        BenchmarkFeatures: The benchmark features at the specified index.\n    \"\"\"\n    return self.data[idx]\n</code></pre>"},{"location":"api_reference/benchmarks/#mlir_rl_artifact.benchmarks.Benchmarks.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of benchmarks loaded.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The total number of benchmarks.</p> Source code in <code>mlir_rl_artifact/benchmarks.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the number of benchmarks loaded.\n\n    Returns:\n        int: The total number of benchmarks.\n    \"\"\"\n    return len(self.data)\n</code></pre>"},{"location":"api_reference/env/","title":"Env","text":"<p>Reinforcement learning environment for MLIR RL.</p> <p>This module implements the RL environment that simulates MLIR code transformations. It manages the state transitions, reward computation, and execution of transformation sequences. The environment tracks operations across benchmarks and evaluates the effectiveness of optimizations.</p>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env","title":"<code>Env</code>","text":"<p>RL Environment class</p>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.bench_idx","title":"<code>bench_idx</code>  <code>instance-attribute</code>","text":"<p>Index of the selected benchmark</p>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.benchmark_data","title":"<code>benchmark_data</code>  <code>instance-attribute</code>","text":"<p>Features of the selected benchmark</p>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__action_reward","title":"<code>__action_reward(trans_succeeded, exec_succeeded=None, new_exec_time=None, old_exec_time=None)</code>","text":"<p>Get the reward of the action based on the transformation and execution results.</p> <p>Parameters:</p> Name Type Description Default <code>trans_succeeded</code> <code>bool</code> <p>A flag indicating if the transformation was successful.</p> required <code>exec_succeeded</code> <code>Optional[bool]</code> <p>A flag indicating if the execution was successful. (required if trans succeeded)</p> <code>None</code> <code>new_exec_time</code> <code>Optional[float]</code> <p>The execution time after transformation. (required if exec succeeded)</p> <code>None</code> <code>old_exec_time</code> <code>Optional[float]</code> <p>The original execution time. (required if exec succeeded)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The reward of the action.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __action_reward(self, trans_succeeded: bool, exec_succeeded: Optional[bool] = None, new_exec_time: Optional[int] = None, old_exec_time: Optional[int] = None) -&gt; float:\n    \"\"\"Get the reward of the action based on the transformation and execution results.\n\n    Args:\n        trans_succeeded (bool): A flag indicating if the transformation was successful.\n        exec_succeeded (Optional[bool]): A flag indicating if the execution was successful. (required if trans succeeded)\n        new_exec_time (Optional[float]): The execution time after transformation. (required if exec succeeded)\n        old_exec_time (Optional[float]): The original execution time. (required if exec succeeded)\n\n    Returns:\n        float: The reward of the action.\n    \"\"\"\n    if not trans_succeeded:\n        return -5.0\n\n    assert exec_succeeded is not None\n    if not exec_succeeded:\n        return -20.0\n\n    assert new_exec_time is not None and old_exec_time is not None\n    return self.__speedup_reward(new_exec_time, old_exec_time)\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__apply_sequence","title":"<code>__apply_sequence(seq)</code>","text":"<p>Apply the sequence of actions to the state's code.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>list[Action]</code> <p>the sequence of actions to apply.</p> required <p>Returns:</p> Type Description <code>tuple[Module, list[float]]</code> <p>tuple[str, list[float]]: the resulting code and rewards received for each action in the sequence.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __apply_sequence(self, seq: list[list[Action]]) -&gt; tuple[Module, list[float]]:\n    \"\"\"Apply the sequence of actions to the state's code.\n\n    Args:\n        seq (list[Action]): the sequence of actions to apply.\n\n    Returns:\n        tuple[str, list[float]]: the resulting code and rewards received for each action in the sequence.\n    \"\"\"\n    rewards: list[float] = []\n    with Context():\n        module = Module.parse(self.benchmark_data.code)\n    for op_seq in reversed(seq):\n        op_seq_already_failed = False\n        for action in op_seq:\n            # We need to assign the same reward to all sub actions\n            rewards_count = len(action.sub_actions) + 1\n\n            if op_seq_already_failed:\n                rewards.extend([0.0] * rewards_count)\n                continue\n\n            # Attempt to apply the transformation to the code\n            # - If the transformation fails: punish the agent, reset the code, and mark the operation as done\n            try:\n                action.apply(module)\n            except Exception as e:\n                seq_str = '\\n'.join([str(list(map(str, op_seq))) for op_seq in seq])\n                print_error(\n                    f\"Error applying action\\n\"\n                    f\"Action: {repr(action)}\\n\"\n                    f\"Error: {e}\\n\"\n                    f\"Benchmark: {self.benchmark_data.bench_name}\\n\"\n                    f\"Transformations:\\n{seq_str}\"\n                )\n                rewards.extend([self.__action_reward(False)] * rewards_count)\n                op_seq_already_failed = True\n                continue\n\n            rewards.extend([0.0] * rewards_count)\n\n    return module, rewards\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__bench_is_done","title":"<code>__bench_is_done(state)</code>","text":"<p>Check if the benchmark is done.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The current state.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>A flag indicating if the benchmark is done.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __bench_is_done(self, state: OperationState) -&gt; bool:\n    \"\"\"Check if the benchmark is done.\n\n    Args:\n        state (OperationState): The current state.\n\n    Returns:\n        bool: A flag indicating if the benchmark is done.\n    \"\"\"\n    return self.__current_op_index(state) == 0\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__current_op_index","title":"<code>__current_op_index(state)</code>","text":"<p>Get the index of the current operation.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The current state.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The index of the current operation.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __current_op_index(self, state: OperationState) -&gt; int:\n    \"\"\"Get the index of the current operation.\n\n    Args:\n        state (OperationState): The current state.\n\n    Returns:\n        int: The index of the current operation.\n    \"\"\"\n    return self.benchmark_data.operation_tags.index(state.operation_tag)\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__init_op_state","title":"<code>__init_op_state(operation_idx)</code>","text":"<p>Create a new operation state.</p> <p>Parameters:</p> Name Type Description Default <code>operation_idx</code> <code>int</code> <p>The operation index.</p> required <p>Returns:</p> Name Type Description <code>OperationState</code> <code>OperationState</code> <p>The new operation state.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __init_op_state(self, operation_idx: int) -&gt; OperationState:\n    \"\"\"Create a new operation state.\n\n    Args:\n        operation_idx (int): The operation index.\n\n    Returns:\n        OperationState: The new operation state.\n    \"\"\"\n    operation_tag = self.benchmark_data.operation_tags[operation_idx]\n    operation_features = self.benchmark_data.operations[operation_tag].copy()\n\n    for action in operation_features.pre_actions:\n        operation_features = action.update_features(operation_features)\n\n    producer_tag = None\n    producer_operand_idx = None\n    producer_features = None\n    if operation_features.producers:\n        # NOTE: To change with mutliple producers support\n        producer_tag = operation_features.producers[-1][0]\n        # NOTE: To change with mutliple uses support\n        producer_operand_idx = min(idx for t, idx in operation_features.producers if t == producer_tag)\n        producer_features = self.benchmark_data.operations[producer_tag].copy()\n\n    state = OperationState(\n        bench_idx=self.bench_idx,\n        bench_name=self.benchmark_data.bench_name,\n        operation_tag=operation_tag,\n        original_operation_features=self.benchmark_data.operations[operation_tag].copy(),\n        operation_features=operation_features,\n        producer_tag=producer_tag,\n        producer_operand_idx=producer_operand_idx,\n        producer_features=producer_features,\n        transformation_history=[[]],\n        terminal=False,\n    )\n\n    return state\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__speedup_reward","title":"<code>__speedup_reward(new, old)</code>","text":"<p>Get the reward based on the speedup.</p> <p>Parameters:</p> Name Type Description Default <code>new</code> <code>float</code> <p>The new execution time.</p> required <code>old</code> <code>float</code> <p>The old execution time.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The calculated reward.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __speedup_reward(self, new: int, old: int) -&gt; float:\n    \"\"\"Get the reward based on the speedup.\n\n    Args:\n        new (float): The new execution time.\n        old (float): The old execution time.\n\n    Returns:\n        float: The calculated reward.\n    \"\"\"\n\n    # if old &lt; new * 2:\n    #     return math.log(old / (new * 2))\n    # else:\n    #     return old / (new * 2) - 1\n    return math.log10(old / new)\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.__update_state_infos","title":"<code>__update_state_infos(state, action)</code>","text":"<p>Update state infos after applying a transformation.</p> Updated fields are: <ul> <li>transformation_history</li> <li>producers features in case of fusion</li> <li>operation_features (to reflect the transformation)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The current state.</p> required <code>action</code> <code>Action</code> <p>The action taken.</p> required Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def __update_state_infos(self, state: OperationState, action: Action):\n    \"\"\"Update state infos after applying a transformation.\n\n    Notes: Updated fields are:\n        - transformation_history\n        - producers features in case of fusion\n        - operation_features (to reflect the transformation)\n\n    Args:\n        state (OperationState): The current state.\n        action (Action): The action taken.\n    \"\"\"\n    # Record action\n    state.record_action(action)\n\n    # In case of fusion we need to update the producer features as well\n    if isinstance(action, TiledFusion):\n        action.update_producer_features(state, self.benchmark_data)\n\n    # Get updated operation features\n    state.operation_features = action.update_features(state.operation_features)\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.get_next_op_state","title":"<code>get_next_op_state(state)</code>","text":"<p>Get the state that represents the next operation (None if benchmark is done).</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The current state.</p> required <p>Returns:</p> Type Description <code>Optional[OperationState]</code> <p>Optional[OperationState]: The next state. If None then bench is done.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def get_next_op_state(self, state: OperationState) -&gt; Optional[OperationState]:\n    \"\"\"Get the state that represents the next operation (None if benchmark is done).\n\n    Args:\n        state (OperationState): The current state.\n\n    Returns:\n        Optional[OperationState]: The next state. If None then bench is done.\n    \"\"\"\n    # Reset to another benchmark if the current benchmark is done (reached first operation)\n    if self.__bench_is_done(state):\n        return None\n\n    # Build a new state that points to the next operation\n    next_state = self.__init_op_state(self.__current_op_index(state) - 1)\n\n    # Keep track of the transformation history\n    next_state.transformation_history += state.transformation_history\n\n    return next_state\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.reset","title":"<code>reset(benchs, bench_idx=None)</code>","text":"<p>Reset the environment.</p> <p>Parameters:</p> Name Type Description Default <code>benchs</code> <code>Benchmarks</code> <p>The benchmarks dataset.</p> required <code>bench_idx</code> <code>Optional[int]</code> <p>The index of the benchmark to set the environment to. If None, a random benchmark is selected. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>OperationState</code> <code>OperationState</code> <p>The initial state of the environment.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def reset(self, benchs: Benchmarks, bench_idx: Optional[int] = None) -&gt; OperationState:\n    \"\"\"Reset the environment.\n\n    Args:\n        benchs (Benchmarks): The benchmarks dataset.\n        bench_idx (Optional[int]): The index of the benchmark to set the environment to. If None, a random benchmark is selected. Defaults to None.\n\n    Returns:\n        OperationState: The initial state of the environment.\n    \"\"\"\n    # Get the benchmark\n    if bench_idx is None:\n        bench_idx = random.randint(0, len(benchs) - 1)\n    self.bench_idx = bench_idx\n    self.benchmark_data = benchs[bench_idx].copy()\n\n    return self.__init_op_state(-1)\n</code></pre>"},{"location":"api_reference/env/#mlir_rl_artifact.env.Env.step","title":"<code>step(state, action)</code>","text":"<p>Take a step in the environment.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The current state.</p> required <code>action</code> <code>Action</code> <p>The action to take.</p> required <p>Returns:</p> Name Type Description <code>OperationState</code> <code>OperationState</code> <p>The new state after applying the action. The state's terminal flag is set if the action failed, is terminal, or the truncation step limit is reached.</p> Source code in <code>mlir_rl_artifact/env.py</code> <pre><code>def step(self, state: OperationState, action: Action) -&gt; OperationState:\n    \"\"\"Take a step in the environment.\n\n    Args:\n        state (OperationState): The current state.\n        action (Action): The action to take.\n\n    Returns:\n        OperationState: The new state after applying the action. The state's terminal\n            flag is set if the action failed, is terminal, or the truncation step limit\n            is reached.\n    \"\"\"\n    # Copy the current state to introduce the changes throughout the function\n    next_state = state.copy()\n\n    # Update the state infos to reflect the transformation\n    action_failed = False\n    try:\n        self.__update_state_infos(next_state, action)\n    except Exception as e:\n        seq_str = '\\n'.join([str(list(map(str, op_seq))) for op_seq in state.transformation_history])\n        print_error(\n            'Error while expecting action effect\\n'\n            f\"Action: {repr(action)}\\n\"\n            f\"Error: {e}\\n\"\n            f\"Call stack: {traceback.format_exc()}\\n\"\n            f\"Benchmark: {self.benchmark_data.bench_name}\\n\"\n            f\"Transformations:\\n{seq_str}\"\n        )\n        action_failed = True\n\n    # Check if state is terminal\n    next_state.terminal = action.terminal or action_failed or next_state.step_count == Config().truncate\n\n    return next_state\n</code></pre>"},{"location":"api_reference/execution/","title":"Execution","text":"<p>Code execution and caching module for MLIR benchmarks.</p> <p>This module handles the execution of transformed MLIR code, including bufferization, lowering, and performance measurement. It manages an execution cache to avoid redundant computations and interfaces with the MLIR execution engine to measure actual execution times.</p>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution","title":"<code>Execution(exec_data_file=None, main_exec_data=None)</code>","text":"<pre><code>Execution()\n</code></pre><pre><code>Execution(exec_data_file: str)\n</code></pre><pre><code>Execution(\n    exec_data_file: str,\n    main_exec_data: dict[str, dict[str, int]],\n)\n</code></pre> <p>Class that deals with code execution and cache management</p> Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def __init__(self, exec_data_file: Optional[str] = None, main_exec_data: Optional[dict[str, dict[str, int]]] = None):\n    if exec_data_file is None:\n        raise Exception(\"No existing instance of class Execution has been found\")\n\n    self.exec_data_file = exec_data_file\n    self.main_exec_data = main_exec_data\n</code></pre>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.exec_data_file","title":"<code>exec_data_file = exec_data_file</code>  <code>instance-attribute</code>","text":"<p>Path to the local file where exec data is cached</p>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.main_exec_data","title":"<code>main_exec_data = main_exec_data</code>  <code>instance-attribute</code>","text":"<p>External exec data that was read at the beginning of training</p>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.__check_execution_cache","title":"<code>__check_execution_cache(bench_name, cache_key)</code>","text":"<p>Check the execution cache for the given operation state.</p> <p>Parameters:</p> Name Type Description Default <code>bench_name</code> <code>str</code> <p>The benchmark name to check.</p> required <code>cache_key</code> <code>str</code> <p>The cache key to check.</p> required <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Optional[int]: the execution time in nanoseconds if the operation is found in the cache, otherwise None.</p> Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def __check_execution_cache(self, bench_name: str, cache_key: str) -&gt; Optional[int]:\n    \"\"\"Check the execution cache for the given operation state.\n\n    Args:\n        bench_name (str): The benchmark name to check.\n        cache_key (str): The cache key to check.\n\n    Returns:\n        Optional[int]: the execution time in nanoseconds if the operation is found in the cache, otherwise None.\n    \"\"\"\n    # Start by checking the main execution data\n    if self.main_exec_data and bench_name in self.main_exec_data and cache_key in self.main_exec_data[bench_name]:\n        return self.main_exec_data[bench_name][cache_key]\n\n    # If no hit in the main cache file, check the temporary cache file\n    if not self.exec_data_file:\n        return None\n\n    with open(self.exec_data_file, \"r\") as file:\n        data: dict[str, dict[str, int]] = json.load(file)\n\n    if bench_name in data and cache_key in data[bench_name]:\n        return data[bench_name][cache_key]\n\n    # No hit in both cache files\n    return None\n</code></pre>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.__execute_bufferized_code","title":"<code>__execute_bufferized_code(module)</code>","text":"<p>Lowers and runs the given MLIR code using Python bindings, then returns the execution time and assertion result (if the executed code returns the correct result).</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to execute.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Optional[float]: the execution time in seconds.</p> <code>bool</code> <code>bool</code> <p>the assertion result.</p> Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def __execute_bufferized_code(self, module: Module) -&gt; tuple[int, bool]:\n    \"\"\"Lowers and runs the given MLIR code using Python bindings, then returns the execution time and assertion\n    result (if the executed code returns the correct result).\n\n    Args:\n        module (Module): The MLIR module to execute.\n\n    Returns:\n        Optional[float]: the execution time in seconds.\n        bool: the assertion result.\n    \"\"\"\n\n    pass_pipeline = \"\"\"builtin.module(\n        canonicalize,\n        buffer-deallocation-pipeline,\n        convert-bufferization-to-memref,\n        convert-linalg-to-loops,\n        scf-forall-to-parallel,\n        convert-scf-to-openmp,\n        expand-strided-metadata,\n        finalize-memref-to-llvm,\n        convert-scf-to-cf,\n        lower-affine,\n\n        convert-openmp-to-llvm,\n        convert-vector-to-llvm,\n        convert-math-to-llvm,\n        convert-math-to-libm,\n        finalize-memref-to-llvm,\n        convert-func-to-llvm,\n        convert-index-to-llvm,\n        convert-arith-to-llvm,\n        convert-cf-to-llvm,\n\n        reconcile-unrealized-casts,\n        canonicalize,\n        cse\n    )\"\"\"\n\n    pm = PassManager.parse(pass_pipeline, module.context)\n\n    inputs, outs_struct = self.__create_params(module)\n    args = self.__convert_to_args(inputs, outs_struct)\n\n    pm.run(module.operation)\n    execution_engine = ExecutionEngine(\n        module,\n        opt_level=3,\n        shared_libs=os.getenv(\"MLIR_SHARED_LIBS\", \"\").split(\",\"),\n    )\n\n    try:\n        times = []\n        for _ in range(5):\n            execution_engine.invoke(\"main\", *args)\n            # If output tensors are needed call `get_results` before `free_outputs`\n            outs_struct.free_outputs()\n            times.append(outs_struct.delta)\n    finally:\n        outs_struct.free_outputs()\n\n    return median(times), True\n</code></pre>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.execute_code","title":"<code>execute_code(module, bench_name, seq)</code>","text":"<p>Executes the given MLIR module and measures execution time.</p> <p>Checks the execution cache first for code matching this sequence. If not found, applies bufferization and lowering transforms before executing the code.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to execute.</p> required <code>bench_name</code> <code>str</code> <p>The benchmark name for cache management.</p> required <code>seq</code> <code>list[list[Action]]</code> <p>The sequence of transformations applied to reach this code.</p> required <p>Returns:</p> Type Description <code>tuple[int, bool, bool]</code> <p>tuple[int, bool, bool]: A tuple containing: - Execution time in nanoseconds - Boolean indicating if execution succeeded - Boolean indicating if this is a cache miss (True if executed, False if cached)</p> Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def execute_code(self, module: Module, bench_name: str, seq: list[list['Action']]) -&gt; tuple[int, bool, bool]:\n    \"\"\"Executes the given MLIR module and measures execution time.\n\n    Checks the execution cache first for code matching this sequence. If not found,\n    applies bufferization and lowering transforms before executing the code.\n\n    Args:\n        module (Module): The MLIR module to execute.\n        bench_name (str): The benchmark name for cache management.\n        seq (list[list[Action]]): The sequence of transformations applied to reach this code.\n\n    Returns:\n        tuple[int, bool, bool]: A tuple containing:\n            - Execution time in nanoseconds\n            - Boolean indicating if execution succeeded\n            - Boolean indicating if this is a cache miss (True if executed, False if cached)\n    \"\"\"\n    code_cache_key = self.get_code_cache_key(seq)\n    cache_exec_time = self.__check_execution_cache(bench_name, code_cache_key)\n    if cache_exec_time is not None:\n        return cache_exec_time, True, False\n\n    transform_bufferize_and_lower_v(module)\n    real_exec_time, success = self.__execute_bufferized_code_wrapper(module)\n    return real_exec_time, success, True\n</code></pre>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.get_code_cache_key","title":"<code>get_code_cache_key(seq)</code>","text":"<p>Get the code cache key for the given operation state.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>list[list[Action]]</code> <p>The sequence of transformations applied to reach this code.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the code cache key.</p> Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def get_code_cache_key(self, seq: list[list['Action']]) -&gt; str:\n    \"\"\"Get the code cache key for the given operation state.\n\n    Args:\n        seq (list[list[Action]]): The sequence of transformations applied to reach this code.\n\n    Returns:\n        str: the code cache key.\n    \"\"\"\n    ops_codes = []\n    for op_seq in seq:\n        # TODO: There might be edge cases where part of a seq is invalid `env.py:301`\n        ops_codes.append(''.join(map(str, op_seq)))\n\n    return '|'.join(ops_codes)\n</code></pre>"},{"location":"api_reference/execution/#mlir_rl_artifact.execution.Execution.update_execution_cache","title":"<code>update_execution_cache(new_data)</code>","text":"<p>Update the temp execution cache with the new data.</p> <p>Parameters:</p> Name Type Description Default <code>new_data</code> <code>dict[str, dict[str, int]]</code> <p>The new data to update.</p> required Source code in <code>mlir_rl_artifact/execution.py</code> <pre><code>def update_execution_cache(self, new_data: dict[str, dict[str, int]]):\n    \"\"\"Update the temp execution cache with the new data.\n\n    Args:\n        new_data (dict[str, dict[str, int]]): The new data to update.\n    \"\"\"\n    if not self.exec_data_file:\n        raise Exception(\"Execution data file not provided\")\n\n    with open(self.exec_data_file, \"r\") as file:\n        data: dict[str, dict[str, int]] = json.load(file)\n\n    for bench_name, bench_data in new_data.items():\n        if bench_name not in data:\n            data[bench_name] = {}\n        data[bench_name].update(bench_data)\n\n    try:\n        with open(self.exec_data_file + \".tmp\", \"w\") as file:\n            json.dump(data, file, indent=4)\n            file.flush()\n            os.fsync(file.fileno())\n        os.replace(self.exec_data_file + \".tmp\", self.exec_data_file)\n    finally:\n        if os.path.exists(self.exec_data_file + \".tmp\"):\n            os.remove(self.exec_data_file + \".tmp\")\n</code></pre>"},{"location":"api_reference/model/","title":"Model","text":"<p>Neural network models for MLIR RL policy and value estimation.</p> <p>This module implements the deep RL components including the policy model, value model, and LSTM-based observation embedding. The policy model outputs action distributions for different transformation types, while the value model estimates state values for advantage computation.</p>"},{"location":"api_reference/model/#mlir_rl_artifact.model.HiearchyModel","title":"<code>HiearchyModel()</code>","text":"<p>               Bases: <code>Module</code></p> <p>Hierarchical reinforcement learning model for MLIR code optimization.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the model.\"\"\"\n    super(HiearchyModel, self).__init__()\n\n    self.policy_model = PolicyModel()\n    self.value_model = ValueModel()\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.HiearchyModel.__call__","title":"<code>__call__(obs, actions_index)</code>","text":"<p>Call the forward method.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <code>actions_index</code> <code>Tensor</code> <p>The indices of actions.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The log probabilities of actions, values, and entropies.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __call__(self, obs: torch.Tensor, actions_index: torch.Tensor) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Call the forward method.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n        actions_index (torch.Tensor): The indices of actions.\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The log probabilities of actions, values, and entropies.\n    \"\"\"\n    return super().__call__(obs, actions_index)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.HiearchyModel.forward","title":"<code>forward(obs, actions_index)</code>","text":"<p>Forward pass of the hierarchical model.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <code>actions_index</code> <code>Tensor</code> <p>The indices of actions.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The log probabilities of actions, values, and entropies.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def forward(self, obs: torch.Tensor, actions_index: torch.Tensor) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Forward pass of the hierarchical model.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n        actions_index (torch.Tensor): The indices of actions.\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The log probabilities of actions, values, and entropies.\n    \"\"\"\n    actions_log_p, entropies = ActionSpace.distributions_stats(self.policy_model(obs), actions_index)\n\n    values = self.value_model(obs)\n\n    return actions_log_p, values, entropies\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.HiearchyModel.sample","title":"<code>sample(obs, greedy=False, eps=None)</code>","text":"<p>Sample an action from the model.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <code>greedy</code> <code>bool</code> <p>Whether to sample greedily.</p> <code>False</code> <code>eps</code> <code>Optional[float]</code> <p>Epsilon value for exploration. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Sampled actions index.</p> <code>Tensor</code> <p>torch.Tensor: actions log probability.</p> <code>Tensor</code> <p>torch.Tensor: resulting entropy.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def sample(self, obs: torch.Tensor, greedy: bool = False, eps: Optional[float] = None) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Sample an action from the model.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n        greedy (bool): Whether to sample greedily.\n        eps (Optional[float]): Epsilon value for exploration. Defaults to None.\n\n    Returns:\n        torch.Tensor: Sampled actions index.\n        torch.Tensor: actions log probability.\n        torch.Tensor: resulting entropy.\n    \"\"\"\n    assert not greedy or eps is None, 'Cannot be greedy and explore at the same time.'\n\n    # Model feedforward\n    distributions = self.policy_model(obs)\n    eps_distributions = ActionSpace.uniform_distributions(obs)\n    actions_index = ActionSpace.sample(\n        obs,\n        distributions,\n        eps_distributions,\n        uniform=eps is not None and torch.rand(1).item() &lt; eps,\n        greedy=greedy\n    )\n    actions_log_p, entropies = ActionSpace.distributions_stats(\n        distributions,\n        actions_index,\n        eps_distributions=eps_distributions if eps is not None else None,\n        eps=eps\n    )\n\n    return actions_index, actions_log_p, entropies\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.LSTMEmbedding","title":"<code>LSTMEmbedding()</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM-based embedding layer for observation encoding.</p> <p>Encodes operation features into a dense embedding using bidirectional LSTM layers.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __init__(self):\n    super(LSTMEmbedding, self).__init__()\n\n    embedding_size = 411\n\n    self.output_size = embedding_size + ActionHistory.size()\n\n    self.embedding = nn.Sequential(\n        nn.Linear(OpFeatures.size(), 512),\n        nn.ELU(),\n        nn.Dropout(0.225),\n        nn.Linear(512, 512),\n        nn.ELU(),\n        nn.Dropout(0.225),\n    )\n\n    self.lstm = nn.LSTM(512, embedding_size)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.LSTMEmbedding.__call__","title":"<code>__call__(obs)</code>","text":"<p>Call the forward method.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The embedded tensor.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __call__(self, obs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Call the forward method.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        torch.Tensor: The embedded tensor.\n    \"\"\"\n    return super().__call__(obs)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.LSTMEmbedding.forward","title":"<code>forward(obs)</code>","text":"<p>Forward pass of the LSTM embedding.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The embedded tensor.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def forward(self, obs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the LSTM embedding.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        torch.Tensor: The embedded tensor.\n    \"\"\"\n    consumer_feats = Observation.get_part(obs, OpFeatures)\n    producer_feats = Observation.get_part(obs, ProducerOpFeatures)\n\n    consumer_embeddings = self.embedding(consumer_feats).unsqueeze(0)\n    producer_embeddings = self.embedding(producer_feats).unsqueeze(0)\n\n    _, (final_hidden, _) = self.lstm(torch.cat((consumer_embeddings, producer_embeddings)))\n\n    return torch.cat((final_hidden.squeeze(0), Observation.get_part(obs, ActionHistory)), 1)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.PolicyModel","title":"<code>PolicyModel()</code>","text":"<p>               Bases: <code>Module</code></p> <p>Policy model for MLIR code optimization.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the model.\"\"\"\n    super(PolicyModel, self).__init__()\n\n    self.log_std = Interchange.log_std\n\n    self.lstm = LSTMEmbedding()\n\n    self.backbone = nn.Sequential(\n        nn.Linear(self.lstm.output_size, 512),\n        ACTIVATION(),\n        nn.Linear(512, 512),\n        ACTIVATION(),\n        nn.Linear(512, 512),\n        ACTIVATION(),\n    )\n\n    output_sizes = [ActionSpace.size()] + [action.network_output_size() for action in ActionSpace.supported_actions]\n    self.heads = nn.ModuleList()\n    for output_size in output_sizes:\n        if not output_size:\n            self.heads.append(None)\n            continue\n        self.heads.append(nn.Sequential(\n            nn.Linear(512, 512),\n            ACTIVATION(),\n            nn.Linear(512, output_size)\n        ))\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.PolicyModel.__call__","title":"<code>__call__(obs)</code>","text":"<p>Call the forward method.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>list[Optional[Distribution]]</code> <p>list[Optional[Distribution]]: The distributions for each action.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __call__(self, obs: torch.Tensor) -&gt; list[Optional[Distribution]]:\n    \"\"\"Call the forward method.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        list[Optional[Distribution]]: The distributions for each action.\n    \"\"\"\n    return super().__call__(obs)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.PolicyModel.forward","title":"<code>forward(obs)</code>","text":"<p>Forward pass of the policy model.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>list[Optional[Distribution]]</code> <p>list[Optional[Distribution]]: The distributions for each action.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def forward(self, obs: torch.Tensor) -&gt; list[Optional[Distribution]]:\n    \"\"\"Forward pass of the policy model.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        list[Optional[Distribution]]: The distributions for each action.\n    \"\"\"\n    embedded = self.backbone(self.lstm(obs))\n    actions_logits = [head(embedded) if head else None for head in self.heads]\n\n    return ActionSpace.distributions(obs, *actions_logits)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.PolicyModel.loss","title":"<code>loss(actions_log_p, actions_bev_log_p, off_policy_rates, advantages, clip_range=0.2)</code>","text":"<p>Calculate the policy loss.</p> <p>Parameters:</p> Name Type Description Default <code>actions_log_p</code> <code>Tensor</code> <p>The log probabilities of the new actions.</p> required <code>actions_bev_log_p</code> <code>Tensor</code> <p>The log probabilities of the actions under the behavior policy.</p> required <code>off_policy_rates</code> <code>Tensor</code> <p>The rate between the old policy and the behavioral (mu) policy.</p> required <code>advantages</code> <code>Tensor</code> <p>The advantages of the actions.</p> required <code>clip_range</code> <code>float</code> <p>The clipping range for the policy loss.</p> <code>0.2</code> <p>Returns:</p> Name Type Description <code>Tensor</code> <p>torch.Tensor: The policy loss.</p> <code>float</code> <code>Tensor</code> <p>The ratio clip fraction (for logging purposes)</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def loss(self, actions_log_p: torch.Tensor, actions_bev_log_p: torch.Tensor, off_policy_rates: torch.Tensor, advantages: torch.Tensor, clip_range: float = 0.2) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculate the policy loss.\n\n    Args:\n        actions_log_p (torch.Tensor): The log probabilities of the new actions.\n        actions_bev_log_p (torch.Tensor): The log probabilities of the actions under the behavior policy.\n        off_policy_rates (torch.Tensor): The rate between the old policy and the behavioral (mu) policy.\n        advantages (torch.Tensor): The advantages of the actions.\n        clip_range (float): The clipping range for the policy loss.\n\n    Returns:\n        torch.Tensor: The policy loss.\n        float: The ratio clip fraction (for logging purposes)\n    \"\"\"\n    ratios = torch.exp(torch.clamp(actions_log_p - actions_bev_log_p, -80.0, 80.0))\n    surr1 = ratios * advantages\n    surr2 = torch.clamp(ratios, (1 - clip_range) * off_policy_rates, (1 + clip_range) * off_policy_rates) * advantages\n    clip_frac = (torch.abs((ratios / off_policy_rates - 1)) &gt; clip_range).float().mean()\n    return - torch.min(surr1, surr2).mean(), clip_frac\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.ValueModel","title":"<code>ValueModel()</code>","text":"<p>               Bases: <code>Module</code></p> <p>Value model for MLIR code optimization.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the model.\"\"\"\n    super(ValueModel, self).__init__()\n\n    self.lstm = LSTMEmbedding()\n\n    self.network = nn.Sequential(\n        nn.Linear(self.lstm.output_size, 512),\n        ACTIVATION(),\n        nn.Linear(512, 512),\n        ACTIVATION(),\n        nn.Linear(512, 512),\n        ACTIVATION(),\n        nn.Linear(512, 1),\n    )\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.ValueModel.__call__","title":"<code>__call__(obs)</code>","text":"<p>Call the forward method.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The value tensor.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def __call__(self, obs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Call the forward method.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        torch.Tensor: The value tensor.\n    \"\"\"\n    return super().__call__(obs)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.ValueModel.forward","title":"<code>forward(obs)</code>","text":"<p>Forward pass of the value model.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The value tensor.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def forward(self, obs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the value model.\n\n    Args:\n        obs (torch.Tensor): The input tensor.\n\n    Returns:\n        torch.Tensor: The value tensor.\n    \"\"\"\n    return self.network(self.lstm(obs)).squeeze(-1)\n</code></pre>"},{"location":"api_reference/model/#mlir_rl_artifact.model.ValueModel.loss","title":"<code>loss(new_values, values, returns)</code>","text":"<p>Calculate the value loss.</p> <p>Parameters:</p> Name Type Description Default <code>new_values</code> <code>Tensor</code> <p>The new value tensor.</p> required <code>values</code> <code>Tensor</code> <p>The value tensor.</p> required <code>returns</code> <code>Tensor</code> <p>The returns tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The value loss.</p> Source code in <code>mlir_rl_artifact/model.py</code> <pre><code>def loss(self, new_values: torch.Tensor, values: torch.Tensor, returns: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Calculate the value loss.\n\n    Args:\n        new_values (torch.Tensor): The new value tensor.\n        values (torch.Tensor): The value tensor.\n        returns (torch.Tensor): The returns tensor.\n\n    Returns:\n        torch.Tensor: The value loss.\n    \"\"\"\n    if Config().value_clip:\n        vclip = values + torch.clamp(new_values - values, -0.2, 0.2)\n        vloss1 = (returns - vclip).pow(2)\n        vloss2 = (returns - new_values).pow(2)\n        return torch.max(vloss1, vloss2).mean()\n    return (returns - new_values).pow(2).mean()\n</code></pre>"},{"location":"api_reference/observation/","title":"Observation","text":"<p>Observation encoding for operation state representation.</p> <p>This module provides classes for encoding operation features into observation tensors used by the RL policy and value networks. It includes components for operation features, producer features, action history, action masks, and loop counts.</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ActionHistory","title":"<code>ActionHistory</code>","text":"<p>               Bases: <code>ObservationPart</code></p> <p>Class representing action history in the observation</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ActionMask","title":"<code>ActionMask</code>","text":"<p>               Bases: <code>ObservationPart</code></p> <p>Class representing action mask in the observation</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.NumLoops","title":"<code>NumLoops</code>","text":"<p>               Bases: <code>ObservationPart</code></p> <p>Class representing number of loops in the observation</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation","title":"<code>Observation</code>","text":"<p>Class to manage creation and use of observations</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.parts","title":"<code>parts = [OpFeatures, ProducerOpFeatures, ActionHistory, NumLoops, ActionMask]</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of observation parts.</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.cumulative_sizes","title":"<code>cumulative_sizes()</code>  <code>classmethod</code>","text":"<p>Get cumulative sizes of all observation parts.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef cumulative_sizes(cls) -&gt; list[int]:\n    \"\"\"Get cumulative sizes of all observation parts.\"\"\"\n    sizes = [0]\n    for part in cls.parts:\n        sizes.append(sizes[-1] + part.size())\n    return sizes\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.from_state","title":"<code>from_state(state)</code>  <code>classmethod</code>","text":"<p>Create the full observation from the current state.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef from_state(cls, state: OperationState) -&gt; torch.Tensor:\n    \"\"\"Create the full observation from the current state.\"\"\"\n    obs_parts = [part.from_state(state) for part in cls.parts]\n    return torch.cat(obs_parts).unsqueeze(0)\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.from_states","title":"<code>from_states(states)</code>  <code>classmethod</code>","text":"<p>Create the full observation for all the states.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef from_states(cls, states: list[OperationState]) -&gt; torch.Tensor:\n    \"\"\"Create the full observation for all the states.\"\"\"\n    return torch.cat([cls.from_state(s) for s in states])\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.get_part","title":"<code>get_part(obs, part, squeeze=True)</code>  <code>classmethod</code>","text":"<p>Get a specific part of the observation.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef get_part(cls, obs: torch.Tensor, part: type[ObservationPart], squeeze: bool = True) -&gt; torch.Tensor:\n    \"\"\"Get a specific part of the observation.\"\"\"\n    part_idx = cls.part_number(part)\n    cum_sizes = cls.cumulative_sizes()\n    start = cum_sizes[part_idx]\n    if part.size() == 1 and squeeze:\n        return obs[:, start]\n    end = cum_sizes[part_idx + 1]\n    return obs[:, start:end]\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.get_parts","title":"<code>get_parts(obs, *parts)</code>  <code>classmethod</code>","text":"<p>Get multiple parts of the observation in a single tensor.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef get_parts(cls, obs: torch.Tensor, *parts: type[ObservationPart]) -&gt; torch.Tensor:\n    \"\"\"Get multiple parts of the observation in a single tensor.\"\"\"\n    return torch.cat([cls.get_part(obs, part, False) for part in parts], dim=1)\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.Observation.part_number","title":"<code>part_number(part)</code>  <code>classmethod</code>","text":"<p>Get the index of a part in the observation.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef part_number(cls, part: type[ObservationPart]) -&gt; int:\n    \"\"\"Get the index of a part in the observation.\"\"\"\n    return cls.parts.index(part)\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ObservationPart","title":"<code>ObservationPart</code>","text":"<p>Abstract base class for observation parts.</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ObservationPart.from_state","title":"<code>from_state(state)</code>  <code>classmethod</code>","text":"<p>Create the observation part from the current state.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef from_state(cls, state: OperationState) -&gt; torch.Tensor:\n    \"\"\"Create the observation part from the current state.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ObservationPart.size","title":"<code>size()</code>  <code>classmethod</code>","text":"<p>Get the size of this observation part.</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@classmethod\ndef size(cls) -&gt; int:\n    \"\"\"Get the size of this observation part.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.OpFeatures","title":"<code>OpFeatures</code>","text":"<p>               Bases: <code>ObservationPart</code></p> <p>Class representing operation features in the observation</p>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.OpFeatures.__formula_str_to_list","title":"<code>__formula_str_to_list(formula)</code>  <code>staticmethod</code>","text":"<p>Turns assignement formula to a list of (index, factor) Example:     formula = \"%x1 - %x2 + %x3 * 5 - %x5 * 3\"     return [('%x1', 1), ('%x2', -1), ('%x3', 5), ('%x5', -3)]</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>the formula as a string input</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[tuple[str, int]]</code> <p>list of (index, factor) pairs</p> Source code in <code>mlir_rl_artifact/observation.py</code> <pre><code>@staticmethod\ndef __formula_str_to_list(formula: str) -&gt; list[tuple[str, int]]:\n    \"\"\"Turns assignement formula to a list of (index, factor)\n    Example:\n        formula = \"%x1 - %x2 + %x3 * 5 - %x5 * 3\"\n        return [('%x1', 1), ('%x2', -1), ('%x3', 5), ('%x5', -3)]\n\n    Args:\n        formula (str): the formula as a string input\n\n    Returns:\n        list: list of (index, factor) pairs\n    \"\"\"\n    formula = formula + ' +'\n    terms = formula.split(' ')\n\n    running_factor = 1\n    running_term = None\n\n    save = []\n\n    for term in terms:\n\n        if term.startswith('%'):\n            running_term = term\n        elif term == '+':\n            save.append((running_term, running_factor))\n            running_factor = 1\n        elif term == '-':\n            save.append((running_term, running_factor))\n            running_factor = -1\n        elif term.isnumeric():\n            running_factor *= int(term)\n\n    if save[0][0] is None:\n        save = save[1:]\n\n    return save\n</code></pre>"},{"location":"api_reference/observation/#mlir_rl_artifact.observation.ProducerOpFeatures","title":"<code>ProducerOpFeatures</code>","text":"<p>               Bases: <code>OpFeatures</code></p> <p>Class representing producer operation features in the observation</p>"},{"location":"api_reference/ppo/","title":"PPO","text":"<p>Proximal Policy Optimization (PPO) training algorithm for MLIR RL.</p> <p>This module implements the core PPO training loop including trajectory collection, policy updates, value function updates, and benchmark evaluation. It manages the interaction between the RL environment and the neural network models.</p>"},{"location":"api_reference/ppo/#mlir_rl_artifact.ppo.__execute_states","title":"<code>__execute_states(state, exec_data_file, benchs, main_exec_data)</code>","text":"<p>Execute a benchmark with the transformation sequence stored in state.</p> <p>Worker function for parallel execution. Initializes environment, applies transformations, and measures execution results.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>The operation state containing transformation history.</p> required <code>exec_data_file</code> <code>str</code> <p>Path to the execution cache file.</p> required <code>benchs</code> <code>Benchmarks</code> <p>The benchmark dataset.</p> required <code>main_exec_data</code> <code>Optional[dict]</code> <p>Pre-computed execution data.</p> required <p>Returns:</p> Type Description <code>tuple[list[float], float, Optional[int], bool, float]</code> <p>tuple[list[float], float, Optional[int], bool, float]: Contains: - List of rewards for each action in the sequence - Speedup factor (ratio of original to optimized time) - Execution time in nanoseconds (None if execution failed) - Cache miss flag (False if result was cached) - Worker execution time in seconds</p> Source code in <code>mlir_rl_artifact/ppo.py</code> <pre><code>def __execute_states(state: OperationState, exec_data_file: str, benchs: Benchmarks, main_exec_data: Optional[dict[str, dict[str, int]]]) -&gt; tuple[list[float], float, Optional[int], bool, float]:\n    \"\"\"Execute a benchmark with the transformation sequence stored in state.\n\n    Worker function for parallel execution. Initializes environment, applies transformations,\n    and measures execution results.\n\n    Args:\n        state (OperationState): The operation state containing transformation history.\n        exec_data_file (str): Path to the execution cache file.\n        benchs (Benchmarks): The benchmark dataset.\n        main_exec_data (Optional[dict]): Pre-computed execution data.\n\n    Returns:\n        tuple[list[float], float, Optional[int], bool, float]: Contains:\n            - List of rewards for each action in the sequence\n            - Speedup factor (ratio of original to optimized time)\n            - Execution time in nanoseconds (None if execution failed)\n            - Cache miss flag (False if result was cached)\n            - Worker execution time in seconds\n    \"\"\"\n    print_info(\"Handling benchmark:\", state.bench_name, flush=True)\n    worker_start = time()\n\n    Execution(exec_data_file, main_exec_data)\n    env = Env()\n    env.reset(benchs, state.bench_idx)\n    rewards, speedup, new_exec_time, cache_miss = env.apply_and_run_sequence(state.transformation_history)\n\n    worker_end = time()\n    worker_time = worker_end - worker_start\n\n    return rewards, speedup, new_exec_time, cache_miss, worker_time\n</code></pre>"},{"location":"api_reference/ppo/#mlir_rl_artifact.ppo.collect_trajectory","title":"<code>collect_trajectory(data, model, step)</code>","text":"<p>Collect a trajectory using the model and the environment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Benchmarks</code> <p>The benchmarks dataset.</p> required <code>model</code> <code>HiearchyModel</code> <p>The model to use.</p> required <code>step</code> <code>int</code> <p>The current step of the main loop.</p> required <p>Returns:</p> Name Type Description <code>TrajectoryData</code> <code>TrajectoryData</code> <p>The collected trajectory.</p> Source code in <code>mlir_rl_artifact/ppo.py</code> <pre><code>def collect_trajectory(data: Benchmarks, model: Model, step: int) -&gt; TrajectoryData:\n    \"\"\"Collect a trajectory using the model and the environment.\n\n    Args:\n        data (Benchmarks): The benchmarks dataset.\n        model (Model): The model to use.\n        step (int): The current step of the main loop.\n\n    Returns:\n        TrajectoryData: The collected trajectory.\n    \"\"\"\n    dm = DaskManager()\n    fl = FileLogger()\n    exe = Execution()\n    cfg = Config()\n\n    eps = None\n    if 'epsilon' in cfg.exploration:\n        ratio = step / cfg.nb_iterations\n        final_eps = 0.001\n        eps = final_eps + (cfg.init_epsilon - final_eps) * (1 - ratio)\n\n    print_info(f\"Collecting {cfg.bench_count} benchmarks using {dm.num_workers} workers...\")\n    traj_start = time()\n\n    # Prepare benchmarks to explore\n    indices = torch.randperm(len(data))[:cfg.bench_count].long().tolist()\n    if len(indices) &lt; cfg.bench_count:\n        indices = (indices * cfg.bench_count)[:cfg.bench_count]\n    envs: list[Env] = []\n    states: list[OperationState] = []\n    observations: list[torch.Tensor] = []\n    tcs: list[TrajectoryCollector] = []\n    for idx in indices:\n        env = Env()\n        state = env.reset(data, idx)\n        envs.append(env)\n        states.append(state)\n        observations.append(Observation.from_state(state))\n        tcs.append(TrajectoryCollector())\n\n    with GPUOccupier().gpu_needed():\n        while (active_states := [(i, s) for i, s in enumerate(states) if not s.terminal]):\n            # Sample states that are not terminal yet\n            obss = torch.cat([observations[i] for i, _ in active_states])\n            actions_index, actions_bev_log_p, entropies = model.sample(obss.to(device), eps=eps)\n            actions_index, actions_bev_log_p, entropies = actions_index.cpu(), actions_bev_log_p.cpu(), entropies.cpu()\n            fl['train/entropy'].extend(entropies.tolist())\n\n            # Record data and update states\n            for (i, state), obs, action_index, action_bev_log_p in zip(active_states, obss, actions_index, actions_bev_log_p):\n                obs = obs.unsqueeze(0)\n\n                # Get action and use it to get next state\n                action = ActionSpace.action_by_index(action_index, state)\n                states[i] = next_state = envs[i].step(state, action)\n                observations[i] = next_obs = Observation.from_state(next_state)\n\n                # If the benchmark is not done yet, keep next operation state instead\n                done = False\n                if next_state.terminal:\n                    next_op_state = envs[i].get_next_op_state(next_state)\n                    if next_op_state is not None:\n                        states[i] = next_op_state\n                        observations[i] = Observation.from_state(next_op_state)\n                    else:\n                        done = True\n\n                # Record available data\n                tcs[i].append((\n                    Observation.get_part(obs, NumLoops).long().item(),\n                    action_index.unsqueeze(0),\n                    obs,\n                    next_obs,\n                    action_bev_log_p.item(),\n                    0.0,  # This will be filled after execution\n                    done\n                ))\n\n    traj_end_sampling = time()\n\n    results = dm.map_objs(__execute_states, states, data, exe.main_exec_data, training=True, obj_str=lambda s: s.bench_name)\n\n    traj_end_exec_states = time()\n\n    results = [\n        (*e.failed_seq(s.transformation_history), float(dm.batch_timeout))\n        if not r else r\n        for r, s, e in zip(results, states, envs)\n    ]\n\n    all_rewards, all_speedups, all_exec_times, cache_misses, worker_times = tuple(zip(*results))\n    new_cache_data: dict[str, dict[str, int]] = {}\n    for tc, state, rewards, speedup, exec_time in zip(tcs, states, all_rewards, all_speedups, all_exec_times):\n        # Update trajectory\n        tc.rewards = rewards\n        # Log metrics\n        fl['train/reward'].extend(rewards)\n        fl['train/final_speedup'].append(speedup)\n        # Get new cache data\n        if exec_time is not None:\n            cache_key = exe.get_code_cache_key(state.transformation_history)\n            if state.bench_name not in new_cache_data:\n                new_cache_data[state.bench_name] = {}\n            new_cache_data[state.bench_name][cache_key] = exec_time\n\n    tc = sum(tcs, TrajectoryCollector())\n    exe.update_execution_cache(new_cache_data)\n\n    traj_end = time()\n\n    sampling_time = traj_end_sampling - traj_start\n    exec_states_time = traj_end_exec_states - traj_end_sampling\n    collection_time = traj_end - traj_start\n    print_info((\n        f\"Timings: collection: {timedelta(seconds=collection_time)}\"\n        f\", sampling: {timedelta(seconds=sampling_time)}\"\n        f\", exec: {timedelta(seconds=exec_states_time)}\"\n    ))\n\n    return tc.to_trajectory()\n</code></pre>"},{"location":"api_reference/ppo/#mlir_rl_artifact.ppo.evaluate_benchmarks","title":"<code>evaluate_benchmarks(model, data)</code>","text":"<p>Evaluate the model on all benchmarks and measure optimization results.</p> <p>Runs the trained model in greedy mode on all benchmarks, applies optimizations, and measures the resulting execution times and speedups.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>HiearchyModel</code> <p>The trained model to evaluate.</p> required <code>data</code> <code>Benchmarks</code> <p>The benchmark dataset to evaluate on.</p> required <p>Returns:</p> Type Description <code>tuple[dict[str, int], dict[str, float]]</code> <p>tuple[dict[str, int], dict[str, float]]: A tuple containing: - Dictionary mapping benchmark names to execution times (in nanoseconds) - Dictionary mapping benchmark names to speedup factors</p> Source code in <code>mlir_rl_artifact/ppo.py</code> <pre><code>def evaluate_benchmarks(model: Model, data: Benchmarks) -&gt; tuple[dict[str, int], dict[str, float]]:\n    \"\"\"Evaluate the model on all benchmarks and measure optimization results.\n\n    Runs the trained model in greedy mode on all benchmarks, applies optimizations,\n    and measures the resulting execution times and speedups.\n\n    Args:\n        model (Model): The trained model to evaluate.\n        data (Benchmarks): The benchmark dataset to evaluate on.\n\n    Returns:\n        tuple[dict[str, int], dict[str, float]]: A tuple containing:\n            - Dictionary mapping benchmark names to execution times (in nanoseconds)\n            - Dictionary mapping benchmark names to speedup factors\n    \"\"\"\n    dm = DaskManager()\n    fl = FileLogger()\n    exe = Execution()\n\n    print_info(\"Evaluation started...\")\n    eval_start = time()\n\n    # Prepare benchmarks to explore\n    indices = range(len(data))\n    envs: list[Env] = []\n    states: list[OperationState] = []\n    observations: list[torch.Tensor] = []\n    for idx in indices:\n        env = Env()\n        state = env.reset(data, idx)\n        envs.append(env)\n        states.append(state)\n        observations.append(Observation.from_state(state))\n\n    with GPUOccupier().gpu_needed():\n        while (active_states := [(i, s) for i, s in enumerate(states) if not s.terminal]):\n            # Sample states that are not terminal yet\n            obss = torch.cat([observations[i] for i, _ in active_states])\n            actions_index, _, entropies = model.sample(obss.to(device), greedy=True)\n            actions_index, entropies = actions_index.cpu(), entropies.cpu()\n            fl['eval/entropy'].extend(entropies.tolist())\n\n            # Record data and update states\n            for (i, state), obs, action_index in zip(active_states, obss, actions_index):\n                obs = obs.unsqueeze(0)\n\n                # Get action and use it to get next state\n                action = ActionSpace.action_by_index(action_index, state)\n                states[i] = next_state = envs[i].step(state, action)\n                observations[i] = Observation.from_state(next_state)\n\n                # If the benchmark is not done yet, keep next operation state instead\n                if next_state.terminal:\n                    next_op_state = envs[i].get_next_op_state(next_state)\n                    if next_op_state is not None:\n                        states[i] = next_op_state\n                        observations[i] = Observation.from_state(next_op_state)\n\n    print_success(\"Schedules inferred! Applying optimizations...\", flush=True)\n    results = dm.map_objs(__execute_states, states, data, exe.main_exec_data, training=False, obj_str=lambda s: s.bench_name)\n    results = [\n        (*e.failed_seq(s.transformation_history), float(dm.batch_timeout))\n        if not r else r\n        for r, s, e in zip(results, states, envs)\n    ]\n    all_rewards, all_speedups, all_exec_times, _, _ = tuple(zip(*results))\n    new_cache_data: dict[str, dict[str, int]] = {}\n    bench_execs: dict[str, int] = {}\n    bench_speedups: dict[str, float] = {}\n    for state, rewards, speedup, exec_time in zip(states, all_rewards, all_speedups, all_exec_times):\n        fl['eval/reward'].extend(rewards)\n        fl['eval/cumulative_reward'].append(sum(rewards))\n        fl['eval/final_speedup'].append(speedup)\n        if exec_time is not None:\n            fl[f'eval/exec_time/{state.bench_name}'].append(exec_time)\n            fl[f'eval/speedup/{state.bench_name}'].append(speedup)\n            bench_execs[state.bench_name] = exec_time\n            bench_speedups[state.bench_name] = speedup\n            cache_key = exe.get_code_cache_key(state.transformation_history)\n            if state.bench_name not in new_cache_data:\n                new_cache_data[state.bench_name] = {}\n            new_cache_data[state.bench_name][cache_key] = exec_time\n\n        print_success(\"\\n--------------------\", add_label=False)\n        print_success(\"Bench:\", state.bench_name, add_label=False)\n        print_success(\"Transformations:\", add_label=False)\n        for op_seq in state.transformation_history:\n            op_tag = op_seq[0].operation_tag\n            print_success(f\"  - {op_tag}: {list(map(str, op_seq))}\", add_label=False)\n        print_success(\"Speedup:\", speedup, add_label=False)\n        print_success(\"Execution time:\", exec_time, add_label=False)\n        print_success(\"--------------------\\n\", add_label=False)\n\n    if len(all_speedups) &gt; 0:\n        fl['eval/average_speedup'].append(sum(all_speedups) / len(all_speedups))\n    exe.update_execution_cache(new_cache_data)\n\n    eval_end = time()\n    print_info(f\"Evaluation time: {timedelta(seconds=eval_end - eval_start)}\")\n\n    return bench_execs, bench_speedups\n</code></pre>"},{"location":"api_reference/ppo/#mlir_rl_artifact.ppo.ppo_update","title":"<code>ppo_update(trajectory, model, optimizer)</code>","text":"<p>Update the policy and value models using PPO algorithm.</p> <p>Performs PPO training on the collected trajectory data by computing policy loss, value loss, and entropy bonus, then updating model parameters via backpropagation.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>TrajectoryData</code> <p>The trajectory data collected from environment.</p> required <code>model</code> <code>HiearchyModel</code> <p>The model to update.</p> required <code>optimizer</code> <code>Optimizer</code> <p>The optimizer for model parameters.</p> required Source code in <code>mlir_rl_artifact/ppo.py</code> <pre><code>def ppo_update(trajectory: TrajectoryData, model: Model, optimizer: torch.optim.Optimizer) -&gt; None:\n    \"\"\"Update the policy and value models using PPO algorithm.\n\n    Performs PPO training on the collected trajectory data by computing policy loss,\n    value loss, and entropy bonus, then updating model parameters via backpropagation.\n\n    Args:\n        trajectory (TrajectoryData): The trajectory data collected from environment.\n        model (Model): The model to update.\n        optimizer (torch.optim.Optimizer): The optimizer for model parameters.\n    \"\"\"\n    fl = FileLogger()\n    cfg = Config()\n\n    trajectory.update_attributes(model)\n\n    ppo_start = time()\n    data_loader = trajectory.loader(cfg.ppo_batch_size, 1)\n    for _ in range(cfg.ppo_epochs):\n        for batch in data_loader:\n            batch: list[torch.Tensor] = [e.to(device, non_blocking=True) for e in batch]\n            (\n                _,\n                actions_index,\n                obs,\n                _,\n                actions_bev_log_p,\n                _, _,\n                values,\n                _,\n                actions_old_log_p,\n                off_policy_rates,\n                returns,\n                advantages,\n            ) = batch\n            max_abs_adv = advantages.abs().max()\n            if cfg.normalize_adv == 'standard' and advantages.size(0) &gt; 1:\n                advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n            elif cfg.normalize_adv == 'max-abs' and max_abs_adv &gt; 0:\n                advantages = advantages / max_abs_adv\n\n            with torch.enable_grad():\n                actions_log_p, new_values, entropies = model(obs, actions_index)\n\n                policy_loss, clip_frac = model.policy_model.loss(actions_log_p, actions_bev_log_p, off_policy_rates, advantages)\n                loss = policy_loss\n\n                if cfg.value_epochs == 0:\n                    value_loss = model.value_model.loss(new_values, values, returns)\n                    loss += cfg.value_coef * value_loss\n\n                if 'entropy' in cfg.exploration:\n                    entropy_loss = -entropies.mean()\n                    loss += cfg.entropy_coef * entropy_loss\n\n            approx_kl = (actions_old_log_p - actions_log_p).pow(2).mean() / 2\n\n            optimizer.zero_grad()\n            try:\n                loss.backward()\n                clip_factor = torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n                optimizer.step()\n            except Exception as e:\n                print_error(\n                    'Error during PPO update\\n'\n                    f'Error: {e}'\n                )\n\n            # Logging\n            fl['train_ppo/policy_loss'].append(policy_loss.item())\n            fl['train_ppo/clip_frac'].append(clip_frac.item())\n            fl['train_ppo/clip_factor'].append(clip_factor.item())\n            fl['train_ppo/approx_kl'].append(approx_kl.item())\n            if cfg.value_epochs == 0:\n                fl['train_ppo/value_loss'].append(value_loss.item())\n            if 'entropy' in cfg.exploration:\n                fl['train_ppo/entropy_loss'].append(entropy_loss.item())\n    ppo_end = time()\n    print_info(f\"PPO fit in {timedelta(seconds=ppo_end - ppo_start)}\")\n</code></pre>"},{"location":"api_reference/ppo/#mlir_rl_artifact.ppo.value_update","title":"<code>value_update(trajectory, model, optimizer)</code>","text":"<p>Update the value function model using trajectory data.</p> <p>Trains the value model to predict state values by minimizing MSE loss between predicted and computed returns.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>TrajectoryData</code> <p>The trajectory data with returns computed.</p> required <code>model</code> <code>HiearchyModel</code> <p>The hierarchical model to update.</p> required <code>optimizer</code> <code>Optimizer</code> <p>The optimizer for value model parameters.</p> required Source code in <code>mlir_rl_artifact/ppo.py</code> <pre><code>def value_update(trajectory: TrajectoryData, model: Model, optimizer: torch.optim.Optimizer) -&gt; None:\n    \"\"\"Update the value function model using trajectory data.\n\n    Trains the value model to predict state values by minimizing MSE loss between\n    predicted and computed returns.\n\n    Args:\n        trajectory (TrajectoryData): The trajectory data with returns computed.\n        model (Model): The hierarchical model to update.\n        optimizer (torch.optim.Optimizer): The optimizer for value model parameters.\n    \"\"\"\n    fl = FileLogger()\n    cfg = Config()\n\n    trajectory.update_attributes(model)\n\n    value_start = time()\n    data_loader = trajectory.loader(cfg.value_batch_size, 1)\n    for _ in range(cfg.value_epochs):\n        for batch in data_loader:\n            batch: list[torch.Tensor] = [e.to(device, non_blocking=True) for e in batch]\n            (\n                _, _,\n                obs,\n                _, _, _, _,\n                values,\n                _, _, _,\n                returns,\n                _,\n            ) = batch\n            with torch.enable_grad():\n                new_values = model.value_model(obs)\n\n                loss = model.value_model.loss(new_values, values, returns)\n\n            optimizer.zero_grad()\n            try:\n                loss.backward()\n                clip_factor = torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n                optimizer.step()\n            except Exception as e:\n                print_error(\n                    'Error during Value update\\n'\n                    f'Error: {e}'\n                )\n\n            # Logging\n            fl['train_value/loss'].append(loss.item())\n            fl['train_value/clip_factor'].append(clip_factor.item())\n    value_end = time()\n    print_info(f\"Value fit in {timedelta(seconds=value_end - value_start)}\")\n</code></pre>"},{"location":"api_reference/state/","title":"State","text":"<p>State representation and feature extraction for MLIR operations.</p> <p>This module provides data structures for representing benchmark and operation states, including features like loops, memory accesses, and operation types. It also provides functionality for extracting these features from MLIR AST using the AstDumper tool.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures","title":"<code>BenchmarkFeatures(bench_name, code, operation_tags, operations, root_exec_time)</code>  <code>dataclass</code>","text":"<p>Dataclass to store the benchmark features data.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.bench_name","title":"<code>bench_name</code>  <code>instance-attribute</code>","text":"<p>The benchmark's name.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.code","title":"<code>code</code>  <code>instance-attribute</code>","text":"<p>The MLIR code of the benchmark.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.operation_tags","title":"<code>operation_tags</code>  <code>instance-attribute</code>","text":"<p>List of operation tags.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.operations","title":"<code>operations</code>  <code>instance-attribute</code>","text":"<p>List of operations where each operation is represented by the OperationFeatures dataclass.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.root_exec_time","title":"<code>root_exec_time</code>  <code>instance-attribute</code>","text":"<p>Execution time of the benchmark in nanoseconds without any transformation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.BenchmarkFeatures.copy","title":"<code>copy()</code>","text":"<p>Copy the current BenchmarkFeatures object.</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the current BenchmarkFeatures object.\"\"\"\n    return BenchmarkFeatures(\n        self.bench_name,\n        self.code,\n        self.operation_tags.copy(),\n        {tag: op.copy() for tag, op in self.operations.items()},\n        self.root_exec_time\n    )\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.IteratorType","title":"<code>IteratorType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of iterator types for loop dimensions.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures","title":"<code>NestedLoopFeatures(arg, lower_bound, upper_bound, step, iterator_type)</code>  <code>dataclass</code>","text":"<p>Dataclass to store the nested loops features data.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.arg","title":"<code>arg</code>  <code>instance-attribute</code>","text":"<p>The argument representing the loop iterator.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.iterator_type","title":"<code>iterator_type</code>  <code>instance-attribute</code>","text":"<p>The type of the loop iterator.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.lower_bound","title":"<code>lower_bound</code>  <code>instance-attribute</code>","text":"<p>The lower bound of the loop.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.step","title":"<code>step</code>  <code>instance-attribute</code>","text":"<p>The loop step.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.upper_bound","title":"<code>upper_bound</code>  <code>instance-attribute</code>","text":"<p>The upper bound of the loop.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.NestedLoopFeatures.copy","title":"<code>copy()</code>","text":"<p>Copy the current NestedLoopFeatures object.</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the current NestedLoopFeatures object.\"\"\"\n    return NestedLoopFeatures(self.arg, self.lower_bound, self.upper_bound, self.step, self.iterator_type)\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures","title":"<code>OperationFeatures(operation_name, operation_type, op_count, load_data, store_data, nested_loops, producers, consumers, vectorizable, pre_actions)</code>  <code>dataclass</code>","text":"<p>Dataclass to store the operation features data.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.consumers","title":"<code>consumers</code>  <code>instance-attribute</code>","text":"<p>List of tags of operations that consume the current operation</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.load_data","title":"<code>load_data</code>  <code>instance-attribute</code>","text":"<p>List of load accesses where each load is represented by the list of access arguments.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.nested_loops","title":"<code>nested_loops</code>  <code>instance-attribute</code>","text":"<p>List of nested loops where each loop is represented by the NestedLoopFeatures dataclass.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.op_count","title":"<code>op_count</code>  <code>instance-attribute</code>","text":"<p>Number of arithmetic operations in the operation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.operation_name","title":"<code>operation_name</code>  <code>instance-attribute</code>","text":"<p>The name of the mlir operation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.operation_type","title":"<code>operation_type</code>  <code>instance-attribute</code>","text":"<p>The type of the operation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.pre_actions","title":"<code>pre_actions</code>  <code>instance-attribute</code>","text":"<p>List actions that are already applied the current operatiom</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.producers","title":"<code>producers</code>  <code>instance-attribute</code>","text":"<p>List of tags of operations that are consumed by the current operation along with their operand indices</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.store_data","title":"<code>store_data</code>  <code>instance-attribute</code>","text":"<p>List of store accesses where each store is represented by the list of access arguments.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.vectorizable","title":"<code>vectorizable</code>  <code>instance-attribute</code>","text":"<p>Flag to indicate if the operation is vectorizable.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationFeatures.copy","title":"<code>copy()</code>","text":"<p>Copy the current OperationFeatures object.</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the current OperationFeatures object.\"\"\"\n    return OperationFeatures(\n        self.operation_name,\n        self.operation_type,\n        self.op_count.copy(),\n        [load.copy() for load in self.load_data],\n        [store.copy() for store in self.store_data],\n        [loop.copy() for loop in self.nested_loops],\n        self.producers.copy(),\n        self.consumers.copy(),\n        self.vectorizable,\n        self.pre_actions.copy()\n    )\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState","title":"<code>OperationState(bench_idx, bench_name, operation_tag, original_operation_features, operation_features, producer_tag, producer_operand_idx, producer_features, transformation_history, terminal)</code>  <code>dataclass</code>","text":""},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.bench_idx","title":"<code>bench_idx</code>  <code>instance-attribute</code>","text":"<p>The benchmark's index.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.bench_name","title":"<code>bench_name</code>  <code>instance-attribute</code>","text":"<p>The benchmark's name.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.operation_features","title":"<code>operation_features</code>  <code>instance-attribute</code>","text":"<p>Features of the operation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.operation_tag","title":"<code>operation_tag</code>  <code>instance-attribute</code>","text":"<p>Tag used to identify the operation in the MLIR code.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.original_operation_features","title":"<code>original_operation_features</code>  <code>instance-attribute</code>","text":"<p>Features of the operation that will be kept always unchanged.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.producer_features","title":"<code>producer_features</code>  <code>instance-attribute</code>","text":"<p>Features of the selected producer</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.producer_operand_idx","title":"<code>producer_operand_idx</code>  <code>instance-attribute</code>","text":"<p>The index of the producer's operand</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.producer_tag","title":"<code>producer_tag</code>  <code>instance-attribute</code>","text":"<p>Tag that identifies the selected producer</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.terminal","title":"<code>terminal</code>  <code>instance-attribute</code>","text":"<p>Flag that determines if the state is terminal</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.transformation_history","title":"<code>transformation_history</code>  <code>instance-attribute</code>","text":"<p>List of transformations with their parameters applied to the operation.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationState.copy","title":"<code>copy()</code>","text":"<p>Copy the current OperationState object.</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def copy(self):\n    \"\"\"Copy the current OperationState object.\"\"\"\n    return OperationState(\n        self.bench_idx,\n        self.bench_name,\n        self.operation_tag,\n        self.original_operation_features.copy(),\n        self.operation_features.copy(),\n        self.producer_tag,\n        self.producer_operand_idx,\n        self.producer_features.copy() if self.producer_features is not None else None,\n        [seq.copy() for seq in self.transformation_history],\n        self.terminal\n    )\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.OperationType","title":"<code>OperationType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of operation types for MLIR operations.</p>"},{"location":"api_reference/state/#mlir_rl_artifact.state.__extract_bench_features_from_ast_result","title":"<code>__extract_bench_features_from_ast_result(bench_name, raw_ast_info, root_execution_time)</code>","text":"<p>Extracts benchmark features from the code's AST result and execution time.</p> <p>Parameters:</p> Name Type Description Default <code>bench_name</code> <code>str</code> <p>the benchmark name</p> required <code>raw_ast_info</code> <code>str</code> <p>the raw AST information</p> required <code>root_execution_time</code> <code>int</code> <p>the root execution time</p> required <p>Returns:</p> Name Type Description <code>BenchmarkFeatures</code> <code>BenchmarkFeatures</code> <p>extracted benchmark features</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def __extract_bench_features_from_ast_result(bench_name: str, raw_ast_info: str, root_execution_time: int) -&gt; BenchmarkFeatures:\n    \"\"\"Extracts benchmark features from the code's AST result and execution time.\n\n    Args:\n        bench_name (str): the benchmark name\n        raw_ast_info (str): the raw AST information\n        root_execution_time (int): the root execution time\n\n    Returns:\n        BenchmarkFeatures: extracted benchmark features\n    \"\"\"\n    cfg = Config()\n\n    info, full_code = raw_ast_info.split(\"########################################\")\n    operations_lines, graph_str = info.split('#BEGIN_GRAPH')\n\n    operations_blocks = operations_lines.split('#START_OPERATION')\n    operations_blocks = [block.strip() for block in operations_blocks if block]\n\n    ops_tags = []\n    operations: dict[str, OperationFeatures] = {}\n    true_loads_count: dict[str, int] = {}\n    for operation_block in operations_blocks:\n        rest, operation_tag = operation_block.split(\"#START_TAG\")\n        operation_tag = operation_tag.strip().split(\"\\n\")[0]\n        log_info = f\"- Bench: {bench_name}\\n- Operation: {operation_tag}\"\n\n        operation_name, rest = rest.split(\"#START_VECTORIZABLE\")\n        operation_name = operation_name.strip()\n        operation_type = __get_operation_type(operation_name)\n\n        nested_loops = []\n        op_count = {}\n        load_data: list[list[str]] = []\n        store_data: list[list[str]] = []\n\n        vectorizable_str, rest = rest.split(\"#START_NESTED_LOOPS\")\n        assert vectorizable_str.strip() in [\"true\", \"false\"], f\"Vectorizable string is not valid: {vectorizable_str}\"\n        vectorizable = vectorizable_str.strip() == \"true\"\n\n        nested_loops_str, rest = rest.split(\"#START_LOAD_DATA\")\n        for nested_loop_str in nested_loops_str.strip().split(\"\\n\"):\n            if not nested_loop_str:\n                continue\n            arg, low, high, step, iter = nested_loop_str.strip().split(\" \")\n            nested_loops.append(NestedLoopFeatures(\n                arg=f'%{arg}',\n                lower_bound=int(low),\n                upper_bound=int(high),\n                step=int(step),\n                iterator_type=IteratorType(iter)\n            ))\n        if len(nested_loops) &gt; cfg.max_num_loops:\n            print_error(f\"Number of loops {len(nested_loops)} is not supported\\n\" + log_info)\n            continue\n\n        loads_data_str, rest = rest.split(\"#START_STORE_DATA\")\n        loads_data_str = re.sub(r'd\\d+', lambda m: f'%{m.group()}', loads_data_str)\n        for load_data_str in loads_data_str.strip().split(\"\\n\"):\n            if not load_data_str:\n                continue\n            load_data.append(load_data_str.split(\", \"))\n        if any(len(load) &gt; cfg.max_num_load_store_dim for load in load_data):\n            print_error(f\"Number of load dims {len(load_data[-1])} is not supported\\n\" + log_info)\n            continue\n        true_loads_count[operation_tag] = len(load_data)\n        if len(load_data) &gt; cfg.max_num_stores_loads:\n            # We ignore this overflow, because there are many cases with a huge number of loads\n            load_data = load_data[:cfg.max_num_stores_loads]\n\n        stores_data_str, ops_count_str = rest.split(\"#START_OP_COUNT\")\n        stores_data_str = re.sub(r'd\\d+', lambda m: f'%{m.group()}', stores_data_str)\n        for store_data_str in stores_data_str.strip().split(\"\\n\"):\n            if not store_data_str:\n                continue\n            store_data.append(store_data_str.split(\", \"))\n        if any(len(store) &gt; cfg.max_num_load_store_dim for store in store_data):\n            print_error(f\"Number of store dims {len(store_data[-1])} is not supported\\n\" + log_info)\n            continue\n        if len(store_data) &gt; cfg.max_num_stores_loads:\n            store_data = store_data[:cfg.max_num_stores_loads]\n\n        for op_count_str in ops_count_str.strip().split(\"\\n\"):\n            op, count = op_count_str.strip().split(\" \")\n            op_count[op] = int(count)\n\n        ops_tags.append(operation_tag)\n        operations[operation_tag] = OperationFeatures(\n            operation_name=operation_name,\n            operation_type=operation_type,\n            op_count=op_count,\n            load_data=load_data,\n            store_data=store_data,\n            nested_loops=nested_loops,\n            producers=[],\n            consumers=[],\n            vectorizable=vectorizable,\n            pre_actions=[]\n        )\n\n    # Extracte Producer/Consumer features\n    graph_str = graph_str.replace(\"#END_GRAPH\", \"\")\n    graph_lines = [(line.split(' --&gt; ')[0].split(' '), line.split(' --&gt; ')[1].split(' ')) for line in graph_str.strip().split(\"\\n\") if line]\n\n    for (producer, res_idx), (consumer, op_idx) in graph_lines:\n        op_idx = int(op_idx)\n        res_idx = int(res_idx)\n        if op_idx &gt;= len(operations[consumer].load_data):\n            if 0 &lt;= (op_idx - true_loads_count[consumer]) &lt; len(operations[consumer].store_data):\n                # Case where the index falls within the supported number of stores\n                # -&gt; align the index\n                op_idx = op_idx - true_loads_count[consumer] + len(operations[consumer].load_data)\n            else:\n                # Case where the index falls within unsupported number of loads or stores\n                # -&gt; ignore\n                continue\n\n        operations[consumer].producers.append((producer, op_idx))\n        operations[producer].consumers.append((consumer, res_idx))\n\n    return BenchmarkFeatures(\n        bench_name=bench_name,\n        code=full_code,\n        operation_tags=ops_tags,\n        operations=operations,\n        root_exec_time=root_execution_time,\n    )\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.__get_operation_type","title":"<code>__get_operation_type(operation_name)</code>","text":"<p>Get the operation type from the operation name.</p> <p>Parameters:</p> Name Type Description Default <code>operation_name</code> <code>str</code> <p>The operation name.</p> required <p>Returns:</p> Name Type Description <code>OperationType</code> <code>OperationType</code> <p>The operation type or None if not found.</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def __get_operation_type(operation_name: str) -&gt; OperationType:\n    \"\"\"Get the operation type from the operation name.\n\n    Args:\n        operation_name (str): The operation name.\n\n    Returns:\n        OperationType: The operation type or None if not found.\n    \"\"\"\n    for operation_type in OperationType:\n        if operation_type.value and operation_type.value in operation_name:\n            return operation_type\n    return OperationType.unknown\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.extract_bench_features_from_code","title":"<code>extract_bench_features_from_code(bench_name, code, root_execution_time)</code>","text":"<p>Extract benchmark features from the given code.</p> <p>Parameters:</p> Name Type Description Default <code>bench_name</code> <code>str</code> <p>the benchmark name</p> required <code>code</code> <code>str</code> <p>the code to extract features from</p> required <code>root_execution_time</code> <code>int</code> <p>the root execution time</p> required <p>Returns:</p> Name Type Description <code>BenchmarkFeatures</code> <code>BenchmarkFeatures</code> <p>the extracted benchmark features</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def extract_bench_features_from_code(bench_name: str, code: str, root_execution_time: int) -&gt; BenchmarkFeatures:\n    \"\"\"Extract benchmark features from the given code.\n\n    Args:\n        bench_name (str): the benchmark name\n        code (str): the code to extract features from\n        root_execution_time (int): the root execution time\n\n    Returns:\n        BenchmarkFeatures: the extracted benchmark features\n    \"\"\"\n    result = subprocess.run(\n        f'{os.getenv(\"AST_DUMPER_BIN_PATH\")} -',\n        shell=True,\n        input=code.encode('utf-8'),\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    raw_ast_info = result.stdout.decode('utf-8')\n    if result.returncode != 0:\n        raise Exception(result.stderr.decode('utf-8'))\n\n    return __extract_bench_features_from_ast_result(bench_name, raw_ast_info, root_execution_time)\n</code></pre>"},{"location":"api_reference/state/#mlir_rl_artifact.state.extract_bench_features_from_file","title":"<code>extract_bench_features_from_file(bench_name, file_path, root_execution_time)</code>","text":"<p>Extract benchmark features from the code in the file.</p> <p>Parameters:</p> Name Type Description Default <code>bench_name</code> <code>str</code> <p>the benchmark name</p> required <code>file_path</code> <code>str</code> <p>the file path</p> required <code>root_execution_time</code> <code>int</code> <p>the root execution time</p> required <p>Returns:</p> Name Type Description <code>BenchmarkFeatures</code> <code>BenchmarkFeatures</code> <p>the extracted benchmark features</p> Source code in <code>mlir_rl_artifact/state.py</code> <pre><code>def extract_bench_features_from_file(bench_name: str, file_path: str, root_execution_time: int) -&gt; BenchmarkFeatures:\n    \"\"\"Extract benchmark features from the code in the file.\n\n    Args:\n        bench_name (str): the benchmark name\n        file_path (str): the file path\n        root_execution_time (int): the root execution time\n\n    Returns:\n        BenchmarkFeatures: the extracted benchmark features\n    \"\"\"\n    result = subprocess.run(\n        f'{os.getenv(\"AST_DUMPER_BIN_PATH\")} {file_path}',\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    raw_ast_info = result.stdout.decode('utf-8')\n    if result.returncode != 0:\n        raise Exception(result.stderr.decode('utf-8'))\n\n    return __extract_bench_features_from_ast_result(bench_name, raw_ast_info, root_execution_time)\n</code></pre>"},{"location":"api_reference/trajectory/","title":"Trajectory","text":"<p>Trajectory data structures and utilities for RL training.</p> <p>This module provides classes for collecting and managing trajectory data during RL training, including trajectory storage, data loading, advantage computation, and experience replay. It implements the TrajectoryData dataset interface and trajectory collection utilities.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.DYNAMIC_ATTRS","title":"<code>DYNAMIC_ATTRS = ['values', 'next_values', 'actions_old_log_p', 'off_policy_rates', 'returns', 'advantages']</code>  <code>module-attribute</code>","text":"<p>List of dynamic attributes that are computed during trajectory processing.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.T_timestep","title":"<code>T_timestep = tuple[int, torch.Tensor, torch.Tensor, torch.Tensor, float, float, bool]</code>  <code>module-attribute</code>","text":"<p>Type alias for a single timestep in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TopKAdvantageSampler","title":"<code>TopKAdvantageSampler(data_source, num_samples)</code>","text":"<p>               Bases: <code>Sampler[int]</code></p> <p>Sampler that yields indices of top-K advantage samples in random order.</p> <p>Selects the top-K samples with highest absolute advantage values for experience replay. This focuses training on the most impactful samples.</p> <p>Attributes:</p> Name Type Description <code>data_source</code> <code>TrajectoryData</code> <p>The trajectory dataset.</p> <code>num_samples</code> <code>int</code> <p>Maximum number of top samples to include.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __init__(self, data_source: 'TrajectoryData', num_samples: int):\n    self.data_source = data_source\n    self.num_samples = num_samples\n\n    # Get all advantage values from the dataset\n    advantages = self.data_source.advantages\n\n    # Ensure we don't request more samples than available\n    self.num_samples = min(self.num_samples, advantages.size(0))\n\n    _, self.top_k_indices = torch.topk(advantages.abs(), k=self.num_samples)\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TopKAdvantageSampler.__iter__","title":"<code>__iter__()</code>","text":"<p>Returns an iterator over shuffled indices of the top-k samples. This is called by the DataLoader at the start of each epoch.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __iter__(self) -&gt; Iterator[int]:\n    \"\"\"\n    Returns an iterator over shuffled indices of the top-k samples.\n    This is called by the DataLoader at the start of each epoch.\n    \"\"\"\n    # Shuffle the top-k indices to ensure random order\n    shuffled_indices = self.top_k_indices[torch.randperm(self.num_samples)]\n\n    # Yield the indices one by one\n    yield from shuffled_indices.tolist()\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TopKAdvantageSampler.__len__","title":"<code>__len__()</code>","text":"<p>The total number of samples to be drawn.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"The total number of samples to be drawn.\"\"\"\n    return self.num_samples\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector","title":"<code>TrajectoryCollector()</code>","text":"<p>Class that appends timestep data to a trajectory.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the trajectory collector.\"\"\"\n    self.num_loops = []\n    self.actions_index = []\n    self.obs = []\n    self.next_obs = []\n    self.actions_bev_log_p = []\n    self.rewards = []\n    self.done = []\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.actions_bev_log_p","title":"<code>actions_bev_log_p = []</code>  <code>instance-attribute</code>","text":"<p>Action log probabilities following behavioral policy in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.actions_index","title":"<code>actions_index = []</code>  <code>instance-attribute</code>","text":"<p>Actions in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.done","title":"<code>done = []</code>  <code>instance-attribute</code>","text":"<p>Done flags in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.next_obs","title":"<code>next_obs = []</code>  <code>instance-attribute</code>","text":"<p>Observations of next states in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.num_loops","title":"<code>num_loops = []</code>  <code>instance-attribute</code>","text":"<p>Number of loops in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.obs","title":"<code>obs = []</code>  <code>instance-attribute</code>","text":"<p>Observations in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.rewards","title":"<code>rewards = []</code>  <code>instance-attribute</code>","text":"<p>Rewards in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.append","title":"<code>append(timestep)</code>","text":"<p>Append a single timestep to the trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>timestep</code> <code>T_timestep</code> <p>The timestep data to append.</p> required Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def append(self, timestep: T_timestep):\n    \"\"\"Append a single timestep to the trajectory.\n\n    Args:\n        timestep (T_timestep): The timestep data to append.\n    \"\"\"\n    self.num_loops.append(timestep[0])\n    self.actions_index.append(timestep[1])\n    self.obs.append(timestep[2])\n    self.next_obs.append(timestep[3])\n    self.actions_bev_log_p.append(timestep[4])\n    self.rewards.append(timestep[5])\n    self.done.append(timestep[6])\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.reset","title":"<code>reset()</code>","text":"<p>Reset the trajectory collector.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def reset(self):\n    \"\"\"Reset the trajectory collector.\"\"\"\n    self.num_loops.clear()\n    self.actions_index.clear()\n    self.obs.clear()\n    self.next_obs.clear()\n    self.actions_bev_log_p.clear()\n    self.rewards.clear()\n    self.done.clear()\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryCollector.to_trajectory","title":"<code>to_trajectory()</code>","text":"<p>Convert the collected data to a TrajectoryData object.</p> <p>Returns:</p> Name Type Description <code>TrajectoryData</code> <code>TrajectoryData</code> <p>The trajectory containing all collected data.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def to_trajectory(self) -&gt; TrajectoryData:\n    \"\"\"Convert the collected data to a TrajectoryData object.\n\n    Returns:\n        TrajectoryData: The trajectory containing all collected data.\n    \"\"\"\n    return TrajectoryData(\n        num_loops=torch.tensor(self.num_loops, dtype=torch.int64),\n        actions_index=torch.cat(self.actions_index),\n        obs=torch.cat(self.obs),\n        next_obs=torch.cat(self.next_obs),\n        actions_bev_log_p=torch.tensor(self.actions_bev_log_p, dtype=torch.float32),\n        rewards=torch.tensor(self.rewards, dtype=torch.float32),\n        done=torch.tensor(self.done, dtype=torch.bool),\n    )\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData","title":"<code>TrajectoryData(num_loops, actions_index, obs, next_obs, actions_bev_log_p, rewards, done)</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Dataset to store the trajectory data.</p> <p>Parameters:</p> Name Type Description Default <code>num_loops</code> <code>Tensor</code> <p>Number of loops in the trajectory.</p> required <code>actions_index</code> <code>Tensor</code> <p>Actions indices in the trajectory.</p> required <code>obs</code> <code>Tensor</code> <p>Observations in the trajectory.</p> required <code>next_obs</code> <code>Tensor</code> <p>Observations of next states in the trajectory.</p> required <code>actions_bev_log_p</code> <code>Tensor</code> <p>Action log probabilities following behavioral policy.</p> required <code>rewards</code> <code>Tensor</code> <p>Rewards in the trajectory.</p> required <code>done</code> <code>Tensor</code> <p>Done flags in the trajectory.</p> required Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __init__(\n    self,\n    num_loops: torch.Tensor,\n    actions_index: torch.Tensor,\n    obs: torch.Tensor,\n    next_obs: torch.Tensor,\n    actions_bev_log_p: torch.Tensor,\n    rewards: torch.Tensor,\n    done: torch.Tensor\n):\n    self.num_loops = num_loops\n    self.actions_index = actions_index\n    self.obs = obs\n    self.next_obs = next_obs\n    self.actions_bev_log_p = actions_bev_log_p\n    self.rewards = rewards\n    self.done = done\n\n    self.sizes = [len(self)]\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.actions_bev_log_p","title":"<code>actions_bev_log_p = actions_bev_log_p</code>  <code>instance-attribute</code>","text":"<p>Action log probabilities following behavioral policy in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.actions_index","title":"<code>actions_index = actions_index</code>  <code>instance-attribute</code>","text":"<p>Actions in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.actions_old_log_p","title":"<code>actions_old_log_p</code>  <code>instance-attribute</code>","text":"<p>Action log probabilities following old policy in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.advantages","title":"<code>advantages</code>  <code>instance-attribute</code>","text":"<p>Advantages in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.done","title":"<code>done = done</code>  <code>instance-attribute</code>","text":"<p>Done flags in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.next_obs","title":"<code>next_obs = next_obs</code>  <code>instance-attribute</code>","text":"<p>Observations of next states in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.next_values","title":"<code>next_values</code>  <code>instance-attribute</code>","text":"<p>Values of actions in the trajectory with one additional step (shifted to one step in the future).</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.num_loops","title":"<code>num_loops = num_loops</code>  <code>instance-attribute</code>","text":"<p>Number of loops in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.obs","title":"<code>obs = obs</code>  <code>instance-attribute</code>","text":"<p>Observations in the trajectory</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.off_policy_rates","title":"<code>off_policy_rates</code>  <code>instance-attribute</code>","text":"<p>Off-policy rates (rho) for the current policy.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.returns","title":"<code>returns</code>  <code>instance-attribute</code>","text":"<p>Returns in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.rewards","title":"<code>rewards = rewards</code>  <code>instance-attribute</code>","text":"<p>Rewards in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.sizes","title":"<code>sizes = [len(self)]</code>  <code>instance-attribute</code>","text":"<p>Sizes of all the included trajectories</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.values","title":"<code>values</code>  <code>instance-attribute</code>","text":"<p>Values of actions in the trajectory.</p>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenate this trajectory with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>TrajectoryData</code> <p>The other trajectory to concatenate with</p> required <p>Returns:</p> Name Type Description <code>TrajectoryData</code> <code>TrajectoryData</code> <p>The trajectory containing both</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __add__(self, other: 'TrajectoryData') -&gt; 'TrajectoryData':\n    \"\"\"Concatenate this trajectory with another.\n\n    Args:\n        other (TrajectoryData): The other trajectory to concatenate with\n\n    Returns:\n        TrajectoryData: The trajectory containing both\n    \"\"\"\n    self_other_sizes = self.sizes + other.sizes\n\n    # Truncate to 10 trajectories\n    self_other_sizes = self_other_sizes[-Config().replay_count:]\n    start = - sum(self_other_sizes)\n    assert len(self_other_sizes) &lt;= Config().replay_count\n\n    self_other = TrajectoryData(\n        torch.cat((self.num_loops, other.num_loops))[start:],\n        torch.cat((self.actions_index, other.actions_index))[start:],\n        torch.cat((self.obs, other.obs))[start:],\n        torch.cat((self.next_obs, other.next_obs))[start:],\n        torch.cat((self.actions_bev_log_p, other.actions_bev_log_p))[start:],\n        torch.cat((self.rewards, other.rewards))[start:],\n        torch.cat((self.done, other.done))[start:],\n    )\n    for attr in DYNAMIC_ATTRS:\n        if hasattr(self, attr) and hasattr(other, attr):\n            self_val = getattr(self, attr)\n            other_val = getattr(other, attr)\n            assert isinstance(self_val, torch.Tensor) and isinstance(other_val, torch.Tensor)\n            setattr(self_other, attr, torch.cat((self_val, other_val))[start:])\n\n    self_other.sizes = self_other_sizes\n\n    assert len(self_other) == sum(self_other_sizes)\n\n    return self_other\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__compute_gae","title":"<code>__compute_gae(gamma=1.0, lambda_=0.95)</code>","text":"<p>Compute the Generalized Advantage Estimation.</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>float</code> <p>discount factor.</p> <code>1.0</code> <code>lambda_</code> <code>float</code> <p>GAE factor.</p> <code>0.95</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: advantages.</p> <code>Tensor</code> <p>torch.Tensor: returns.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __compute_gae(self, gamma: float = 1.0, lambda_: float = 0.95) -&gt; torch.Tensor:\n    \"\"\"Compute the Generalized Advantage Estimation.\n\n    Args:\n        gamma (float): discount factor.\n        lambda_ (float): GAE factor.\n\n    Returns:\n        torch.Tensor: advantages.\n        torch.Tensor: returns.\n    \"\"\"\n    self.advantages = torch.zeros(len(self), dtype=torch.float32)\n    last_advantage = 0\n\n    for t in reversed(range(len(self))):\n        mask = ~self.done[t]\n        last_value = self.next_values[t] * mask\n        last_advantage = last_advantage * mask\n\n        delta = self.rewards[t] + gamma * last_value - self.values[t]\n        last_advantage = delta + gamma * lambda_ * last_advantage\n\n        self.advantages[t] = last_advantage\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__compute_returns","title":"<code>__compute_returns(gamma=1.0)</code>","text":"<p>Compute the returns.</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>float</code> <p>discount factor. Defaults to 1.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: returns.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __compute_returns(self, gamma: float = 1.0) -&gt; torch.Tensor:\n    \"\"\"Compute the returns.\n\n    Args:\n        gamma (float): discount factor. Defaults to 1.\n\n    Returns:\n        torch.Tensor: returns.\n    \"\"\"\n    self.returns = torch.zeros(len(self), dtype=torch.float32)\n    last_return = 0\n\n    for t in reversed(range(len(self))):\n        mask = ~self.done[t]\n        last_return = last_return * mask\n\n        last_return = self.values[t] + (self.rewards[t] + gamma * last_return - self.values[t]) * self.off_policy_rates[t].clamp_max(1)\n\n        self.returns[t] = last_return\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__compute_rho","title":"<code>__compute_rho()</code>","text":"<p>Compute the off-policy rate (rho) for the current policy.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The off-policy rate.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __compute_rho(self) -&gt; torch.Tensor:\n    \"\"\"Compute the off-policy rate (rho) for the current policy.\n\n    Returns:\n        torch.Tensor: The off-policy rate.\n    \"\"\"\n    if 'epsilon' not in Config().exploration and Config().reuse_experience == 'none':\n        self.off_policy_rates = torch.ones_like(self.actions_bev_log_p)\n        return\n\n    self.off_policy_rates = torch.exp(torch.clamp(self.actions_old_log_p - self.actions_bev_log_p, -80.0, 80.0))\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Get a single timestep from the trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the timestep to retrieve.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, ...]</code> <p>tuple[torch.Tensor, ...]: A tuple containing the timestep data.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; tuple[torch.Tensor, ...]:\n    \"\"\"Get a single timestep from the trajectory.\n\n    Args:\n        idx (int): Index of the timestep to retrieve.\n\n    Returns:\n        tuple[torch.Tensor, ...]: A tuple containing the timestep data.\n    \"\"\"\n    return (\n        self.num_loops[idx],\n        self.actions_index[idx],\n        self.obs[idx],\n        self.next_obs[idx],\n        self.actions_bev_log_p[idx],\n        self.rewards[idx],\n        self.done[idx],\n\n        self.values[idx],\n        self.next_values[idx],\n        self.actions_old_log_p[idx],\n        self.off_policy_rates[idx],\n        self.returns[idx],\n        self.advantages[idx],\n    )\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.__len__","title":"<code>__len__()</code>","text":"<p>Get the length of the trajectory.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The length of the trajectory.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Get the length of the trajectory.\n\n    Returns:\n        int: The length of the trajectory.\n    \"\"\"\n    return self.obs.size(0)\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.copy","title":"<code>copy()</code>","text":"<p>Copy the trajectory.</p> <p>Returns:</p> Name Type Description <code>TrajectoryData</code> <code>TrajectoryData</code> <p>The copied trajectory.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def copy(self) -&gt; 'TrajectoryData':\n    \"\"\"Copy the trajectory.\n\n    Returns:\n        TrajectoryData: The copied trajectory.\n    \"\"\"\n    self_copy = TrajectoryData(\n        num_loops=self.num_loops.clone(),\n        actions_index=self.actions_index.clone(),\n        obs=self.obs.clone(),\n        next_obs=self.next_obs.clone(),\n        actions_bev_log_p=self.actions_bev_log_p.clone(),\n        rewards=self.rewards.clone(),\n        done=self.done.clone(),\n    )\n    for attr in DYNAMIC_ATTRS:\n        if hasattr(self, attr):\n            attr_val = getattr(self, attr)\n            assert isinstance(attr_val, torch.Tensor)\n            setattr(self_copy, attr, attr_val.clone())\n\n    self_copy.sizes = self.sizes.copy()\n\n    return self_copy\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.loader","title":"<code>loader(batch_size, num_trajectories)</code>","text":"<p>Create a DataLoader for the trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for the DataLoader.</p> required <code>num_trajectories</code> <code>int</code> <p>Number of trajectories to use for training.</p> required <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>The DataLoader for the trajectory.</p> Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def loader(self, batch_size: Optional[int], num_trajectories: int) -&gt; DataLoader:\n    \"\"\"Create a DataLoader for the trajectory.\n\n    Args:\n        batch_size (int): Batch size for the DataLoader.\n        num_trajectories (int): Number of trajectories to use for training.\n\n    Returns:\n        DataLoader: The DataLoader for the trajectory.\n    \"\"\"\n    num_samples = sum(self.sizes[-num_trajectories:])\n    if batch_size is None:\n        batch_size = num_samples\n    match Config().reuse_experience:\n        case 'topk':\n            sampler = TopKAdvantageSampler(self, num_samples)\n        case 'random':\n            sampler = RandomSampler(self, num_samples=num_samples)\n        case 'none':\n            sampler = None\n\n    return DataLoader(\n        self,\n        batch_size=batch_size,\n        shuffle=sampler is None,\n        sampler=sampler,\n        pin_memory=device.type != 'cpu',\n        drop_last=True\n    )\n</code></pre>"},{"location":"api_reference/trajectory/#mlir_rl_artifact.trajectory.TrajectoryData.update_attributes","title":"<code>update_attributes(model)</code>","text":"<p>Update the attributes of the trajectory following the new model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>HiearchyModel</code> <p>The model to use for updating the attributes.</p> required Source code in <code>mlir_rl_artifact/trajectory.py</code> <pre><code>def update_attributes(self, model: Model):\n    \"\"\"Update the attributes of the trajectory following the new model.\n\n    Args:\n        model (Model): The model to use for updating the attributes.\n    \"\"\"\n    start = time()\n\n    actions_old_log_p, values, _ = model(self.obs.to(device), self.actions_index.to(device))\n    self.actions_old_log_p, self.values = actions_old_log_p.cpu(), values.cpu()\n\n    self.next_values = model.value_model(self.next_obs.to(device)).cpu()\n\n    self.__compute_rho()\n    self.__compute_returns()\n    self.__compute_gae()\n    end = time()\n    time_ms = int((end - start) * 1000)\n    print_info(f\"Updated {len(self)} attributes in {time_ms}ms\")\n</code></pre>"},{"location":"api_reference/transforms/","title":"Transforms","text":"<p>MLIR transformation passes for loop optimization.</p> <p>This module provides functions for applying various loop transformation passes to MLIR code, including tiling, interchange, parallelization, vectorization, and fusion. It interfaces with the MLIR transform dialect for specifying and applying transformations.</p>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.__run_transform_code","title":"<code>__run_transform_code(module, transform_code)</code>","text":"<p>Parse and apply MLIR transform dialect code to a module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>transform_code</code> <code>str</code> <p>The MLIR transform dialect code.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def __run_transform_code(module: Module, transform_code: str) -&gt; None:\n    \"\"\"Parse and apply MLIR transform dialect code to a module.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        transform_code (str): The MLIR transform dialect code.\n    \"\"\"\n    t_module = Module.parse(transform_code, module.context)\n    interpreter.apply_named_sequence(module, t_module.body.operations[0], t_module)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.__run_transform_code_wrapper","title":"<code>__run_transform_code_wrapper(module, transform_code)</code>","text":"<p>Wrapper for running transform code with timeout support.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>transform_code</code> <code>str</code> <p>The MLIR transform dialect code.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def __run_transform_code_wrapper(module: Module, transform_code: str) -&gt; None:\n    \"\"\"Wrapper for running transform code with timeout support.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        transform_code (str): The MLIR transform dialect code.\n    \"\"\"\n    BindingsProcess.call(__run_transform_code, module, transform_code, timeout=60)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.move_module","title":"<code>move_module(source, destination)</code>","text":"<p>Copy all operations from source module to destination module.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Module</code> <p>The source MLIR module.</p> required <code>destination</code> <code>Module</code> <p>The destination MLIR module where operations will be copied.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def move_module(source: Module, destination: Module) -&gt; None:\n    \"\"\"Copy all operations from source module to destination module.\n\n    Args:\n        source (Module): The source MLIR module.\n        destination (Module): The destination MLIR module where operations will be copied.\n    \"\"\"\n    for op in destination.body.operations:\n        op.erase()\n    for op in source.body.operations:\n        destination.body.append(op.clone())\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_TF","title":"<code>transform_TF(module, consumer_tag, producer_tag, new_producer_tag, tiling_sizes)</code>","text":"<p>Apply tiling and fusion transformation to consumer and producer operations.</p> <p>Tiles the consumer with parallelization and fuses the producer into the tiled loops.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>consumer_tag</code> <code>str</code> <p>The tag of the consumer operation.</p> required <code>producer_tag</code> <code>str</code> <p>The tag of the producer operation to fuse.</p> required <code>new_producer_tag</code> <code>str</code> <p>The tag to assign to the fused producer.</p> required <code>tiling_sizes</code> <code>list[int]</code> <p>List of tiling factors for consumer loops.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_TF(module: Module, consumer_tag: str, producer_tag: str, new_producer_tag: str, tiling_sizes: list[int]) -&gt; None:\n    \"\"\"Apply tiling and fusion transformation to consumer and producer operations.\n\n    Tiles the consumer with parallelization and fuses the producer into the tiled loops.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        consumer_tag (str): The tag of the consumer operation.\n        producer_tag (str): The tag of the producer operation to fuse.\n        new_producer_tag (str): The tag to assign to the fused producer.\n        tiling_sizes (list[int]): List of tiling factors for consumer loops.\n    \"\"\"\n    # If parallel sizes are all zeros, means no fusion will be done\n    if all([a == 0 for a in tiling_sizes]):\n        return\n\n    transform_code = (\n        f'\\nmodule attributes {{transform.with_named_sequence}} {{\\n'\n        f'  transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\\n'\n        f'    %op_{consumer_tag} = transform.structured.match attributes{{tag = \"{consumer_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %tiled_op_{consumer_tag}, %forall_op_{consumer_tag} = transform.structured.tile_using_forall %op_{consumer_tag} tile_sizes {str(tiling_sizes)} : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)\\n'\n        f'    %op_{producer_tag} = transform.structured.match attributes{{tag = \"{producer_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %fused, %containing = transform.structured.fuse_into_containing_op %op_{producer_tag} into %forall_op_{consumer_tag} : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)\\n'\n        f'    %fused_tag = transform.param.constant \"{new_producer_tag}\" -&gt; !transform.any_param\\n'\n        f'    transform.annotate %fused \"tag\" = %fused_tag : !transform.any_op, !transform.any_param\\n'\n        f'    transform.yield\\n'\n        f'  }}\\n'\n        f'}}\\n'\n    )\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_TP","title":"<code>transform_TP(module, operation_tag, tiling_sizes)</code>","text":"<p>Apply tiling and parallelization transformation to an operation.</p> <p>Tiles loops using forall constructs for parallelization.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to transform.</p> required <code>tiling_sizes</code> <code>list[int]</code> <p>List of tiling factors for each loop.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_TP(module: Module, operation_tag: str, tiling_sizes: list[int]) -&gt; None:\n    \"\"\"Apply tiling and parallelization transformation to an operation.\n\n    Tiles loops using forall constructs for parallelization.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to transform.\n        tiling_sizes (list[int]): List of tiling factors for each loop.\n    \"\"\"\n    # If tiling sizes are all zeros, means no tiling is needed\n    if all([a == 0 for a in tiling_sizes]):\n        return\n\n    # Add full transform dialect code into the main code\n    transform_code = (\n        f'\\nmodule attributes {{transform.with_named_sequence}} {{\\n'\n        f'  transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\\n'\n        f'    %op_{operation_tag} = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %op_tiled_{operation_tag}, %forall_{operation_tag} = transform.structured.tile_using_forall %op_{operation_tag} tile_sizes {str(tiling_sizes)} : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)\\n'\n        f'    transform.yield\\n'\n        f'  }}\\n'\n        f'}}'\n    )\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_bufferize_and_lower_v","title":"<code>transform_bufferize_and_lower_v(module)</code>","text":"<p>Apply bufferization and lowering transformations for vectorized execution.</p> <p>Applies a comprehensive series of transformations including bufferization, vectorization, and lowering to prepare code for execution.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_bufferize_and_lower_v(module: Module) -&gt; None:\n    \"\"\"Apply bufferization and lowering transformations for vectorized execution.\n\n    Applies a comprehensive series of transformations including bufferization,\n    vectorization, and lowering to prepare code for execution.\n\n    Args:\n        module (Module): The MLIR module to transform.\n    \"\"\"\n    transform_code = \"\"\"\n    module attributes {transform.with_named_sequence} {\n        transform.named_sequence @__transform_main(%arg0: !transform.any_op {transform.consumed}) {\n            %all_loops = transform.structured.match interface{LoopLikeInterface} in %arg0 : (!transform.any_op) -&gt; !transform.any_op\n            transform.apply_licm to %all_loops : !transform.any_op\n\n            transform.structured.eliminate_empty_tensors %arg0 : !transform.any_op\n            %empty = transform.structured.match ops{[\"tensor.empty\"]} in %arg0 : (!transform.any_op) -&gt; !transform.op&lt;\"tensor.empty\"&gt;\n            transform.bufferization.empty_tensor_to_alloc_tensor %empty : (!transform.op&lt;\"tensor.empty\"&gt;) -&gt; !transform.op&lt;\"bufferization.alloc_tensor\"&gt;\n\n            %f0 = transform.structured.match ops{[\"func.func\"]} in %arg0 : (!transform.any_op) -&gt; !transform.any_op\n            transform.apply_patterns to %f0 {\n                transform.apply_patterns.vector.transfer_permutation_patterns\n                transform.apply_patterns.vector.reduction_to_contract\n            } : !transform.any_op\n            transform.apply_patterns to %f0 {\n                transform.apply_patterns.canonicalization\n                transform.apply_patterns.tensor.fold_tensor_subset_ops_into_vector_transfers\n            } : !transform.any_op\n\n            %arg1 = transform.bufferization.one_shot_bufferize layout{IdentityLayoutMap} %arg0 {bufferize_function_boundaries = true} : (!transform.any_op) -&gt; !transform.any_op\n\n            %f1 = transform.structured.match ops{[\"func.func\"]} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\n            transform.apply_patterns to %f1 {\n                transform.apply_patterns.vector.lower_contraction lowering_strategy = \"outerproduct\"\n                transform.apply_patterns.vector.transfer_permutation_patterns\n                transform.apply_patterns.vector.lower_multi_reduction lowering_strategy = \"innerparallel\"\n                transform.apply_patterns.vector.split_transfer_full_partial split_transfer_strategy = \"linalg-copy\"\n                transform.apply_patterns.vector.transfer_to_scf max_transfer_rank = 1 full_unroll = true\n                transform.apply_patterns.vector.lower_transfer max_transfer_rank = 1\n                transform.apply_patterns.vector.lower_shape_cast\n                transform.apply_patterns.vector.lower_transpose lowering_strategy = \"shuffle_1d\"\n                transform.apply_patterns.canonicalization\n            } : !transform.any_op\n            transform.yield\n        }\n    }\"\"\"\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_decompose","title":"<code>transform_decompose(module, operation_tag)</code>","text":"<p>Apply decomposition transformation to an operation.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to decompose.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_decompose(module: Module, operation_tag: str) -&gt; None:\n    \"\"\"Apply decomposition transformation to an operation.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to decompose.\n    \"\"\"\n    transform_code = f\"\"\"\n    module attributes {{transform.with_named_sequence}} {{\n        transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\n            %conv = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\n            %decomposed = transform.structured.decompose %conv: (!transform.any_op) -&gt; !transform.any_op\n            %decomposed_tag = transform.param.constant \"{operation_tag}\" -&gt; !transform.any_param\n            transform.annotate %decomposed \"tag\" = %decomposed_tag : !transform.any_op, !transform.any_param\n            transform.yield\n        }}\n    }}\"\"\"\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_img2col","title":"<code>transform_img2col(module, operation_tag)</code>","text":"<p>Apply img2col transformation to convert convolution to matrix multiplication.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the convolution operation to transform.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_img2col(module: Module, operation_tag: str) -&gt; None:\n    \"\"\"Apply img2col transformation to convert convolution to matrix multiplication.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the convolution operation to transform.\n    \"\"\"\n    transform_code = f\"\"\"\nmodule attributes {{transform.with_named_sequence}} {{\n  transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\n    %op_operation = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\n\n    transform.structured.convert_conv2d_to_img2col %op_operation : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)\n\n    transform.yield\n  }}\n}}\"\"\"\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_interchange","title":"<code>transform_interchange(module, operation_tag, interchange_list)</code>","text":"<p>Apply loop interchange transformation to an operation.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to transform.</p> required <code>interchange_list</code> <code>list[int]</code> <p>Permutation of loop indices defining the new loop order.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_interchange(module: Module, operation_tag: str, interchange_list: list[int]) -&gt; None:\n    \"\"\"Apply loop interchange transformation to an operation.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to transform.\n        interchange_list (list[int]): Permutation of loop indices defining the new loop order.\n    \"\"\"\n    # If the permutation list is same as the identity permutation, means no interchange is needed\n    if interchange_list == list(range(len(interchange_list))):\n        return\n\n    transform_code = (\n        f'module attributes {{transform.with_named_sequence}} {{\\n'\n        f'  transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\\n'\n        f'    %op_{operation_tag} = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %gen_op_{operation_tag} = transform.structured.generalize %op_{operation_tag} : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %interchanged_op = transform.structured.interchange %gen_op_{operation_tag} iterator_interchange = {str(interchange_list)} : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %interchanged_tag = transform.param.constant \"{operation_tag}\" -&gt; !transform.any_param\\n'\n        f'    transform.annotate %interchanged_op \"tag\" = %interchanged_tag : !transform.any_op, !transform.any_param\\n'\n        f'    transform.yield\\n'\n        f'  }}\\n'\n        f'}}\\n'\n    )\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_pre_vec","title":"<code>transform_pre_vec(module, operation_tag)</code>","text":"<p>Apply pre-vectorization transformation to eliminate unit-stride accesses.</p> <p>Eliminates accesses with constant 1 stride by adding subviews, which enables better vectorization opportunities.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to transform.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_pre_vec(module: Module, operation_tag: str) -&gt; None:\n    \"\"\"Apply pre-vectorization transformation to eliminate unit-stride accesses.\n\n    Eliminates accesses with constant 1 stride by adding subviews, which enables\n    better vectorization opportunities.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to transform.\n    \"\"\"\n    code_process = subprocess.run(\n        f'{os.getenv(\"PRE_VEC_BIN_PATH\")} - {operation_tag}',\n        shell=True,\n        input=str(module).encode('utf-8'),\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    code = code_process.stdout.decode('utf-8')\n\n    if code_process.returncode != 0:\n        raise Exception(code_process.stderr.decode('utf-8'))\n\n    new_module = Module.parse(code, module.context)\n\n    move_module(new_module, module)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_tile","title":"<code>transform_tile(module, operation_tag, tiling_sizes)</code>","text":"<p>Apply tiling transformation to an operation using for loops.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to transform.</p> required <code>tiling_sizes</code> <code>list[int]</code> <p>List of tiling factors for each loop.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_tile(module: Module, operation_tag: str, tiling_sizes: list[int]) -&gt; None:\n    \"\"\"Apply tiling transformation to an operation using for loops.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to transform.\n        tiling_sizes (list[int]): List of tiling factors for each loop.\n    \"\"\"\n    # If tiling sizes are all zeros, means no tiling is needed\n    if all([a == 0 for a in tiling_sizes]):\n        return\n\n    n_loops = sum([s != 0 for s in tiling_sizes])\n    r = ', '.join(['!transform.any_op'] * n_loops)\n    assert n_loops &gt; 0, \"No loops to tile\"\n\n    transform_code = (\n        f'\\nmodule attributes {{transform.with_named_sequence}} {{\\n'\n        f'  transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\\n'\n        f'    %op_{operation_tag} = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\\n'\n        f'    %tiled_op_{operation_tag}, %loops:{n_loops} = transform.structured.tile_using_for %op_{operation_tag} tile_sizes {str(tiling_sizes)} : (!transform.any_op) -&gt; (!transform.any_op, {r})\\n'\n        f'    transform.yield\\n'\n        f'  }}\\n'\n        f'}}\\n'\n    )\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_transpose_conv_2d","title":"<code>transform_transpose_conv_2d(module, operation_tag)</code>","text":"<p>Apply transposed convolution transformation to an operation.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the convolution operation to transform.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_transpose_conv_2d(module: Module, operation_tag: str) -&gt; None:\n    \"\"\"Apply transposed convolution transformation to an operation.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the convolution operation to transform.\n    \"\"\"\n    transform_code = f\"\"\"\n    module attributes {{transform.with_named_sequence}} {{\n        transform.named_sequence @__transform_main(%arg1: !transform.any_op {{transform.readonly}}) {{\n            %conv = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg1 : (!transform.any_op) -&gt; !transform.any_op\n            %transposed = transform.structured.transpose_conv2d %conv : (!transform.any_op) -&gt; !transform.any_op\n            %transposed_tag = transform.param.constant \"{operation_tag}\" -&gt; !transform.any_param\n            transform.annotate %transposed \"tag\" = %transposed_tag : !transform.any_op, !transform.any_param\n            transform.yield\n        }}\n    }}\"\"\"\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/transforms/#mlir_rl_artifact.transforms.transform_vectorize","title":"<code>transform_vectorize(module, operation_tag)</code>","text":"<p>Apply vectorization transformation to an operation.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The MLIR module to transform.</p> required <code>operation_tag</code> <code>str</code> <p>The tag of the operation to transform.</p> required Source code in <code>mlir_rl_artifact/transforms.py</code> <pre><code>def transform_vectorize(module: Module, operation_tag: str) -&gt; None:\n    \"\"\"Apply vectorization transformation to an operation.\n\n    Args:\n        module (Module): The MLIR module to transform.\n        operation_tag (str): The tag of the operation to transform.\n    \"\"\"\n    transform_code = f\"\"\"\n    module attributes {{transform.with_named_sequence}} {{\n        transform.named_sequence @__transform_main(%arg0: !transform.any_op {{transform.readonly}}) {{\n            %op_{operation_tag} = transform.structured.match attributes{{tag = \"{operation_tag}\"}} in %arg0 : (!transform.any_op) -&gt; !transform.any_op\n            transform.structured.vectorize %op_{operation_tag} : !transform.any_op\n            transform.yield\n        }}\n    }}\"\"\"\n\n    __run_transform_code_wrapper(module, transform_code)\n</code></pre>"},{"location":"api_reference/actions/","title":"Action Space","text":"<p>Action space and transformation action implementations.</p> <p>This module defines all available transformation actions for loop nest optimization, including tiling, parallelization, fusion, interchange, and vectorization. It provides the ActionSpace class for action sampling and distribution management.</p>"},{"location":"api_reference/actions/#mlir_rl_artifact.actions.ActionSpace","title":"<code>ActionSpace</code>","text":"<p>Class holding information about the action space</p>"},{"location":"api_reference/actions/#mlir_rl_artifact.actions.ActionSpace.distributions","title":"<code>distributions(obs, selection_logits, *actions_logits)</code>  <code>classmethod</code>","text":"<p>Create a list of distributions for the actions based on the logits.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>Observation tensor.</p> required <code>selection_logits</code> <code>Tensor</code> <p>Logits for action selection.</p> required <code>*actions_logits</code> <code>Tensor</code> <p>Logits for each action's parameters.</p> <code>()</code> <p>Returns:</p> Type Description <code>list[Optional[Distribution]]</code> <p>list[Distribution]: List of distributions for each action.</p> Source code in <code>mlir_rl_artifact/actions/__init__.py</code> <pre><code>@classmethod\ndef distributions(cls, obs: torch.Tensor, selection_logits: torch.Tensor, *actions_logits: Optional[torch.Tensor]) -&gt; list[Optional[Distribution]]:\n    \"\"\"Create a list of distributions for the actions based on the logits.\n\n    Args:\n        obs (torch.Tensor): Observation tensor.\n        selection_logits (torch.Tensor): Logits for action selection.\n        *actions_logits (torch.Tensor): Logits for each action's parameters.\n\n    Returns:\n        list[Distribution]: List of distributions for each action.\n    \"\"\"\n    from mlir_rl_artifact.observation import Observation, ActionMask\n\n    actions_mask = Observation.get_part(obs, ActionMask).bool()\n    dists_list: list[Optional[Distribution]] = [\n        Categorical(logits=selection_logits.where(actions_mask[:, :cls.size()], -torch.inf))\n    ]\n    cum_sizes = cls.cumulative_mask_sizes()\n    for i, action in enumerate(cls.supported_actions):\n        if not action.mask_size():\n            dists_list.append(None)\n            continue\n\n        assert actions_logits[i] is not None, f\"action '{action.symbol}' must have logits\"\n        masked_logits = actions_logits[i].where(actions_mask[:, cum_sizes[i]:cum_sizes[i + 1]], -torch.inf)\n        dists_list.append(action.distribution(masked_logits))\n\n    return dists_list\n</code></pre>"},{"location":"api_reference/actions/#mlir_rl_artifact.actions.ActionSpace.uniform_distributions","title":"<code>uniform_distributions(obs)</code>  <code>classmethod</code>","text":"<p>Create a list of uniform distributions for the actions based on the observation.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>Tensor</code> <p>Observation tensor.</p> required <p>Returns:</p> Type Description <code>list[Optional[Distribution]]</code> <p>list[Distribution]: List of distributions for each action.</p> Source code in <code>mlir_rl_artifact/actions/__init__.py</code> <pre><code>@classmethod\ndef uniform_distributions(cls, obs: torch.Tensor) -&gt; list[Optional[Distribution]]:\n    \"\"\"Create a list of uniform distributions for the actions based on the observation.\n\n    Args:\n        obs (torch.Tensor): Observation tensor.\n\n    Returns:\n        list[Distribution]: List of distributions for each action.\n    \"\"\"\n    from mlir_rl_artifact.observation import Observation, ActionMask, NumLoops\n\n    actions_mask = Observation.get_part(obs, ActionMask).bool()\n    num_loops = Observation.get_part(obs, NumLoops)\n    selection_mask = actions_mask[:, :cls.size()]\n    dists_list: list[Optional[Distribution]] = [\n        Categorical(logits=torch.zeros_like(selection_mask).where(selection_mask, -torch.inf))\n    ]\n    cum_sizes = cls.cumulative_mask_sizes()\n    for i, action in enumerate(cls.supported_actions):\n        if not action.mask_size():\n            dists_list.append(None)\n            continue\n\n        action_mask = actions_mask[:, cum_sizes[i]:cum_sizes[i + 1]]\n        logits = torch.zeros_like(action_mask).where(action_mask, -torch.inf)\n        dists_list.append(action.uniform_distribution(logits, num_loops))\n\n    return dists_list\n</code></pre>"},{"location":"api_reference/actions/base/","title":"Base","text":"<p>Base action classes for MLIR loop transformations.</p> <p>This module defines the abstract base class for transformation actions and provides the action interface that all concrete transformation actions must implement.</p>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action","title":"<code>Action(arg1=None, arg2=None, /, *, operation_tag=None, **extras)</code>","text":"<pre><code>Action(*, operation_tag: str, **extras)\n</code></pre><pre><code>Action(state: OperationState, /, **extras)\n</code></pre><pre><code>Action(\n    parameters: list[int],\n    /,\n    *,\n    operation_tag: str,\n    **extras,\n)\n</code></pre><pre><code>Action(\n    parameters: list[int],\n    state: OperationState,\n    /,\n    **extras,\n)\n</code></pre> <p>Base action class</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>def __init__(\n    self,\n    arg1: Optional[Union[OperationState, list[int]]] = None,\n    arg2: Optional[OperationState] = None,\n    /, *,\n    operation_tag: Optional[str] = None,\n    **extras\n):\n    if isinstance(arg1, OperationState):\n        parameters = None\n        state = arg1\n    else:\n        parameters = arg1\n        state = arg2\n    if (state is None) == (operation_tag is None):\n        raise ValueError(\"Either state or operation tag must be provided and not both\")\n    if state:\n        operation_tag = state.operation_tag\n    self.operation_tag = operation_tag\n    self.parameters = parameters\n    self.extras = {'operation_tag': operation_tag, **extras}\n    if 'process_params' in self.extras:\n        del self.extras['process_params']\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the action with extra params</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of the action with extra params\"\"\"\n    params_list = list(map(str, self.parameters)) if self.parameters else []\n    params_list.extend(f'{k} = {v}' for k, v in self.extras.items())\n\n    return f\"{self.__class__.__name__}({', '.join(params_list)})\"\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the action</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the action\"\"\"\n    return f\"{self.symbol}({','.join(map(str, self.parameters)) if self.parameters else ''})\"\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.action_history","title":"<code>action_history(seq)</code>  <code>classmethod</code>","text":"<p>Return the action history for this action type in the current state</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>list[Action]</code> <p>sequence of actions in the current state</p> required <p>Returns:</p> Type Description <code>Optional[Tensor]</code> <p>Optional[torch.Tensor]: action history for this action type, or None if not applicable</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef action_history(cls, seq: list['Action']) -&gt; Optional[torch.Tensor]:\n    \"\"\"Return the action history for this action type in the current state\n\n    Args:\n        seq (list[Action]): sequence of actions in the current state\n\n    Returns:\n        Optional[torch.Tensor]: action history for this action type, or None if not applicable\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.action_mask","title":"<code>action_mask(state)</code>  <code>classmethod</code>","text":"<p>Return the action mask for this action type in the current state</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>current state to check the action on</p> required <p>Returns:</p> Type Description <code>Optional[Tensor]</code> <p>Optional[torch.Tensor]: action mask for this action type, or None if not applicable</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef action_mask(cls, state: OperationState) -&gt; Optional[torch.Tensor]:\n    \"\"\"Return the action mask for this action type in the current state\n\n    Args:\n        state (OperationState): current state to check the action on\n\n    Returns:\n        Optional[torch.Tensor]: action mask for this action type, or None if not applicable\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.apply","title":"<code>apply(module)</code>","text":"<p>Apply action on the current code</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>current code to apply the action on</p> required <p>Returns:</p> Name Type Description <code>Module</code> <code>Module</code> <p>the new transformed code</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>def apply(self, module: Module) -&gt; Module:\n    \"\"\"Apply action on the current code\n\n    Args:\n        module (Module): current code to apply the action on\n\n    Returns:\n        Module: the new transformed code\n    \"\"\"\n    if not self.ready:\n        return\n\n    self._apply_ready(module)\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.distribution","title":"<code>distribution(logits)</code>  <code>classmethod</code>","text":"<p>Create a distribution for this action type based on the logits</p> <p>Parameters:</p> Name Type Description Default <code>logits</code> <code>Tensor</code> <p>Logits for the action selection.</p> required <p>Returns:</p> Name Type Description <code>Distribution</code> <code>Distribution</code> <p>A distribution object for this action type.</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef distribution(cls, logits: torch.Tensor) -&gt; Distribution:\n    \"\"\"Create a distribution for this action type based on the logits\n\n    Args:\n        logits (torch.Tensor): Logits for the action selection.\n\n    Returns:\n        Distribution: A distribution object for this action type.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.distribution_stats","title":"<code>distribution_stats(distribution, index, eps_distribution, eps=None)</code>  <code>classmethod</code>","text":"<p>Calculate the log probabilities and entropies for the distribution</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Distribution</code> <p>The distribution to calculate stats for.</p> required <code>eps_distribution</code> <code>Distribution</code> <p>The epsilon distribution for exploration.</p> required <code>index</code> <code>Tensor</code> <p>The params index.</p> required <code>eps</code> <code>Optional[float]</code> <p>Epsilon value for exploration. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor]: Log probabilities and entropies.</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef distribution_stats(cls, distribution: Distribution, index: torch.Tensor, eps_distribution: Optional[Distribution], eps: Optional[float] = None) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculate the log probabilities and entropies for the distribution\n\n    Args:\n        distribution (Distribution): The distribution to calculate stats for.\n        eps_distribution (Distribution): The epsilon distribution for exploration.\n        index (torch.Tensor): The params index.\n        eps (Optional[float]): Epsilon value for exploration. Defaults to None.\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]: Log probabilities and entropies.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.from_str","title":"<code>from_str(state, action_str)</code>  <code>classmethod</code>","text":"<p>Create an action from a string representation</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>current state to apply the action on</p> required <code>action_str</code> <code>str</code> <p>string representation of the action</p> required <p>Returns:</p> Name Type Description <code>Action</code> <code>Action</code> <p>action created from the string representation</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef from_str(cls, state: OperationState, action_str: str) -&gt; 'Action':\n    \"\"\"Create an action from a string representation\n\n    Args:\n        state (OperationState): current state to apply the action on\n        action_str (str): string representation of the action\n\n    Returns:\n        Action: action created from the string representation\n    \"\"\"\n    symbol = action_str.split('(')[0]\n    if symbol != cls.symbol:\n        raise ValueError(f'Symbol mismatch for class {cls.__name__}: {symbol} != {cls.symbol}')\n\n    parameters = list(map(int, action_str.split('(')[1].split(')')[0].split(',')))\n    if not parameters:\n        return cls(state)\n    return cls(parameters, state, process_params=False)\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.history_size","title":"<code>history_size()</code>  <code>classmethod</code>","text":"<p>Return the size of the history for this action type</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>size of the history for this action type</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef history_size(cls) -&gt; int:\n    \"\"\"Return the size of the history for this action type\n\n    Returns:\n        int: size of the history for this action type\n    \"\"\"\n    return 0\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.is_allowed","title":"<code>is_allowed(state)</code>  <code>classmethod</code>","text":"<p>Check if this action type is allowed in the current state</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>OperationState</code> <p>current state to check the action on</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the action is allowed, False otherwise</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef is_allowed(cls, state: OperationState) -&gt; bool:\n    \"\"\"Check if this action type is allowed in the current state\n\n    Args:\n        state (OperationState): current state to check the action on\n\n    Returns:\n        bool: True if the action is allowed, False otherwise\n    \"\"\"\n    return True\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.mask_size","title":"<code>mask_size()</code>  <code>classmethod</code>","text":"<p>Return the size of the mask for this action type</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>size of the mask for this action type</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef mask_size(cls) -&gt; int:\n    \"\"\"Return the size of the mask for this action type\n\n    Returns:\n        int: size of the mask for this action type\n    \"\"\"\n    return cls.network_output_size()\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.network_output_size","title":"<code>network_output_size()</code>  <code>classmethod</code>","text":"<p>Return the size of the network output for this action type</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>size of the network output for this action type</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef network_output_size(cls) -&gt; int:\n    \"\"\"Return the size of the network output for this action type\n\n    Returns:\n        int: size of the network output for this action type\n    \"\"\"\n    return 0\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.params_size","title":"<code>params_size()</code>  <code>classmethod</code>","text":"<p>Return the size of the parameters in the index for this action type</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>size of the parameters for this action type</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef params_size(cls) -&gt; int:\n    \"\"\"Return the size of the parameters in the index for this action type\n\n    Returns:\n        int: size of the parameters for this action type\n    \"\"\"\n    return 0\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.sample","title":"<code>sample(distribution, eps_distribution, num_loops, uniform, greedy)</code>  <code>classmethod</code>","text":"<p>Sample an action based on the distribution</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Distribution</code> <p>The distribution to sample from.</p> required <code>eps_distribution</code> <code>Distribution</code> <p>The epsilon distribution for exploration.</p> required <code>num_loops</code> <code>Tensor</code> <p>Number of loops in the operation state.</p> required <code>uniform</code> <code>bool</code> <p>Whether to sample uniformly.</p> required <code>greedy</code> <code>bool</code> <p>Whether to sample greedily.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Sampled action index.</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef sample(cls, distribution: Distribution, eps_distribution: Distribution, num_loops: torch.Tensor, uniform: bool, greedy: bool) -&gt; torch.Tensor:\n    \"\"\"Sample an action based on the distribution\n\n    Args:\n        distribution (Distribution): The distribution to sample from.\n        eps_distribution (Distribution): The epsilon distribution for exploration.\n        num_loops (torch.Tensor): Number of loops in the operation state.\n        uniform (bool): Whether to sample uniformly.\n        greedy (bool): Whether to sample greedily.\n\n    Returns:\n        torch.Tensor: Sampled action index.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.uniform_distribution","title":"<code>uniform_distribution(logits, num_loops)</code>  <code>classmethod</code>","text":"<p>Create a uniform distribution for this action type based on the logits and number of loops</p> <p>Parameters:</p> Name Type Description Default <code>logits</code> <code>Tensor</code> <p>Logits for the action selection.</p> required <code>num_loops</code> <code>Tensor</code> <p>Number of loops in the operation state.</p> required <p>Returns:</p> Name Type Description <code>Distribution</code> <code>Distribution</code> <p>A uniform distribution object for this action type.</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>@classmethod\ndef uniform_distribution(cls, logits: torch.Tensor, num_loops: torch.Tensor) -&gt; Distribution:\n    \"\"\"Create a uniform distribution for this action type based on the logits and number of loops\n\n    Args:\n        logits (torch.Tensor): Logits for the action selection.\n        num_loops (torch.Tensor): Number of loops in the operation state.\n\n    Returns:\n        Distribution: A uniform distribution object for this action type.\n    \"\"\"\n    return cls.distribution(logits)\n</code></pre>"},{"location":"api_reference/actions/base/#mlir_rl_artifact.actions.base.Action.update_features","title":"<code>update_features(operation_features)</code>","text":"<p>Update the operation features based on the action</p> <p>Parameters:</p> Name Type Description Default <code>operation_features</code> <code>OperationFeatures</code> <p>The operation features to update.</p> required <p>Returns:</p> Name Type Description <code>OperationFeatures</code> <code>OperationFeatures</code> <p>The updated operation features.</p> Source code in <code>mlir_rl_artifact/actions/base.py</code> <pre><code>def update_features(self, operation_features: OperationFeatures) -&gt; OperationFeatures:\n    \"\"\"Update the operation features based on the action\n\n    Args:\n        operation_features (OperationFeatures): The operation features to update.\n\n    Returns:\n        OperationFeatures: The updated operation features.\n    \"\"\"\n    return operation_features\n</code></pre>"},{"location":"api_reference/actions/interchange/","title":"Interchange","text":"<p>Interchange action for MLIR loop transformations.</p> <p>This module implements the loop interchange transformation action, which reorders loop dimensions using different encoding methods (enumerate, pointers, continuous).</p>"},{"location":"api_reference/actions/interchange/#mlir_rl_artifact.actions.interchange.Interchange","title":"<code>Interchange(parameters, state=None, /, *, process_params=True, **extras)</code>","text":"<p>               Bases: <code>Action</code></p> <p>Class representing Interchange action</p> Source code in <code>mlir_rl_artifact/actions/interchange.py</code> <pre><code>def __init__(\n    self,\n    parameters: list[int],\n    state: Optional[OperationState] = None,\n    /, *,\n    process_params: bool = True,\n    **extras\n):\n    if state and process_params:\n        # Case where state is provided -&gt; Parameters need processing\n\n        assert len(parameters) == 1, 'uncompatible parameters for constructor call'\n        parameter = parameters[0]\n        num_loops = len(state.operation_features.nested_loops)\n        match Interchange.method:\n            case InterchangeMethod.EnumeratedCandidates:\n                parameters = self.__get_candidates(num_loops)[parameter]\n            case InterchangeMethod.ContinuousEncoding:\n                parameters = self.__decode_continuous(parameter, num_loops)\n            case InterchangeMethod.LevelsPointers:\n                old_action = self.incomplete_interchange(state)\n                if old_action:\n                    perm_buffer = old_action.parameters\n                else:\n                    perm_buffer = []\n\n                assert parameter not in perm_buffer, 'repitition detected in permutation'\n                parameters = perm_buffer + [parameter]\n                assert len(parameters) &lt;= num_loops, 'interchange parameter exceeds number of loops'\n                if len(parameters) &lt; num_loops:\n                    self.ready = False\n    super().__init__(parameters, state, **extras)\n</code></pre>"},{"location":"api_reference/actions/interchange/#mlir_rl_artifact.actions.interchange.Interchange.log_std","title":"<code>log_std = torch.nn.Parameter(torch.zeros(1))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Log standard deviation for continuous interchange encoding.</p>"},{"location":"api_reference/actions/interchange/#mlir_rl_artifact.actions.interchange.Interchange.__decode_continuous","title":"<code>__decode_continuous(parameter, num_loops)</code>  <code>staticmethod</code>","text":"<p>Decode the interchange parameter to get the loop permutation.</p> <p>Parameters:</p> Name Type Description Default <code>parameter</code> <code>int</code> <p>The interchange parameter.</p> required <code>num_loops</code> <code>int</code> <p>The number of loops in the operation.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: The loop permutation.</p> Source code in <code>mlir_rl_artifact/actions/interchange.py</code> <pre><code>@staticmethod\ndef __decode_continuous(parameter: int, num_loops: int) -&gt; list[int]:\n    \"\"\"Decode the interchange parameter to get the loop permutation.\n\n    Args:\n        parameter (int): The interchange parameter.\n        num_loops (int): The number of loops in the operation.\n\n    Returns:\n        list[int]: The loop permutation.\n    \"\"\"\n    x = parameter\n    n = num_loops\n    if x &gt;= math.factorial(n):\n        raise Exception(f\"Invalid interchange parameter: {x}\")\n\n    # Convert x to factorial number\n    fact_x = '0'\n    q = x\n    d = 2\n    while q &gt; 0:\n        r = q % d\n        q = q // d\n        fact_x = str(r) + fact_x\n        d += 1\n\n    # Ensure to get exactly n digits\n    fact_x = fact_x.zfill(n)[-n:]\n\n    # Decode factorial number following Lehmer code\n    nl = list(map(int, fact_x))\n    for i in range(len(nl) - 2, -1, -1):\n        for j in range(i + 1, len(nl)):\n            if nl[j] &gt;= nl[i]:\n                nl[j] += 1\n\n    return nl\n</code></pre>"},{"location":"api_reference/actions/interchange/#mlir_rl_artifact.actions.interchange.Interchange.__get_candidates","title":"<code>__get_candidates(num_loops)</code>  <code>staticmethod</code>","text":"<p>Get all 1c 2c 3c possible interchanges for <code>num_loops</code></p> <p>Parameters:</p> Name Type Description Default <code>num_loops</code> <code>int</code> <p>The number of loops in the operation.</p> required <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>list[tuple]: The list of all possible interchanges.</p> Source code in <code>mlir_rl_artifact/actions/interchange.py</code> <pre><code>@staticmethod\ndef __get_candidates(num_loops: int) -&gt; list[list[int]]:\n    \"\"\"Get all 1c 2c 3c possible interchanges for `num_loops`\n\n    Args:\n        num_loops (int): The number of loops in the operation.\n\n    Returns:\n        list[tuple]: The list of all possible interchanges.\n    \"\"\"\n\n    interchanges = []\n    for c in [1, 2, 3]:\n        level_interchanges = []\n        for _ in range(Config().max_num_loops - c):\n            level_interchanges.append(list(range(num_loops)))\n        for i in range(num_loops - c):\n            params = list(range(num_loops))\n            params[i], params[i + c] = params[i + c], params[i]\n            level_interchanges[i] = params\n        interchanges += level_interchanges\n    return interchanges\n</code></pre>"},{"location":"api_reference/actions/interchange/#mlir_rl_artifact.actions.interchange.InterchangeMethod","title":"<code>InterchangeMethod</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of interchange encoding methods.</p>"},{"location":"api_reference/actions/no_transformation/","title":"No Transformation","text":"<p>No transformation action for MLIR loop transformations.</p> <p>This module implements the no transformation action, which terminates the transformation sequence without applying any changes.</p>"},{"location":"api_reference/actions/no_transformation/#mlir_rl_artifact.actions.no_transformation.NoTransformation","title":"<code>NoTransformation(state=None, /, **extras)</code>","text":"<p>               Bases: <code>Action</code></p> <p>Class representing No Transformation</p> Source code in <code>mlir_rl_artifact/actions/no_transformation.py</code> <pre><code>def __init__(self, state: Optional[OperationState] = None, /, **extras):\n    super().__init__(state, **extras)\n</code></pre>"},{"location":"api_reference/actions/tiled_fusion/","title":"Tiled Fusion","text":"<p>Tiled fusion action for MLIR loop transformations.</p> <p>This module implements the tiled fusion transformation action, which applies tiling and fusion of producer-consumer operations.</p>"},{"location":"api_reference/actions/tiled_fusion/#mlir_rl_artifact.actions.tiled_fusion.TiledFusion","title":"<code>TiledFusion(parameters, state=None, /, *, producer_tag=None, producer_operand_idx=None, **extras)</code>","text":"<p>               Bases: <code>TiledParallelization</code></p> <p>Class representing Tiled Fusion action</p> Source code in <code>mlir_rl_artifact/actions/tiled_fusion.py</code> <pre><code>def __init__(\n    self,\n    parameters: list[int],\n    state: Optional[OperationState] = None,\n    /, *,\n    producer_tag: Optional[str] = None,\n    producer_operand_idx: Optional[int] = None,\n    **extras\n):\n    args_is_none = [\n        producer_tag is None,\n        producer_operand_idx is None\n    ]\n    if (state is None) in args_is_none:\n        raise ValueError(\"Either state or preprocessing attributes must be provided and not both\")\n    if state:\n        producer_tag = state.producer_tag\n        producer_operand_idx = state.producer_operand_idx\n    assert producer_tag is not None and producer_operand_idx is not None\n    super().__init__(\n        parameters,\n        state,\n        producer_tag=producer_tag,\n        producer_operand_idx=producer_operand_idx,\n        **extras\n    )\n\n    self.producer_tag = producer_tag\n    self.producer_operand_idx = producer_operand_idx\n    self.producer_feats_updated = False\n</code></pre>"},{"location":"api_reference/actions/tiled_fusion/#mlir_rl_artifact.actions.tiled_fusion.TiledFusion.update_producer_features","title":"<code>update_producer_features(state, bench_feats)</code>","text":"<p>Update the features of the prducer after the fusion.</p> Note <ul> <li>This update modifies the bench features inplace</li> <li>Currently we only support having one use in the containing op</li> </ul> Source code in <code>mlir_rl_artifact/actions/tiled_fusion.py</code> <pre><code>def update_producer_features(self, state: OperationState, bench_feats: BenchmarkFeatures):\n    \"\"\"Update the features of the prducer after the fusion.\n\n    Note:\n        - This update modifies the bench features inplace\n        - Currently we only support having one use in the containing op\n    \"\"\"\n    prod_feats = state.producer_features.copy()\n\n    self.__update_consumers_and_producers(prod_feats, state)\n\n    self.__record_implicit_tiling(prod_feats, state)\n\n    self.__insert_in_bench_feats(prod_feats, state, bench_feats)\n\n    self.__handle_producer_original_op(bench_feats)\n\n    self.producer_feats_updated = True\n</code></pre>"},{"location":"api_reference/actions/tiled_parallelization/","title":"Tiled Parallelization","text":"<p>Tiled parallelization action for MLIR loop transformations.</p> <p>This module implements the tiled parallelization transformation action, which applies tiling with parallelization using forall constructs.</p>"},{"location":"api_reference/actions/tiled_parallelization/#mlir_rl_artifact.actions.tiled_parallelization.TiledParallelization","title":"<code>TiledParallelization(parameters, state=None, /, *, iterators=None, **extras)</code>","text":"<p>               Bases: <code>Tiling</code></p> <p>Class representing Tiled Parallelization action</p> Source code in <code>mlir_rl_artifact/actions/tiled_parallelization.py</code> <pre><code>def __init__(\n    self,\n    parameters: list[int],\n    state: Optional[OperationState] = None,\n    /, *,\n    iterators: Optional[list[str]] = None,\n    **extras\n):\n    if (state is None) == (iterators is None):\n        raise ValueError(\"Either state or iterators must be provided and not both\")\n    if state:\n        iterators = [loop.iterator_type.value for loop in state.operation_features.nested_loops]\n    super().__init__(parameters, state, iterators=iterators, **extras)\n\n    self.parallel_params = [\n        0 if iterator == IteratorType.Reduction.value\n        else param for param, iterator in zip(self.parameters, iterators)\n    ]\n    self.tiling_params = [\n        param if iterator == IteratorType.Reduction.value\n        else 0 for param, iterator in zip(self.parameters, iterators)\n    ]\n</code></pre>"},{"location":"api_reference/actions/tiling/","title":"Tiling","text":"<p>Tiling action for MLIR loop transformations.</p> <p>This module implements the tiling transformation action, which applies loop tiling to operations with configurable tile sizes.</p>"},{"location":"api_reference/actions/tiling/#mlir_rl_artifact.actions.tiling.Tiling","title":"<code>Tiling(parameters, state=None, /, *, process_params=True, **extras)</code>","text":"<p>               Bases: <code>Action</code></p> <p>Class representing Tiling action</p> Source code in <code>mlir_rl_artifact/actions/tiling.py</code> <pre><code>def __init__(\n    self,\n    parameters: list[int],\n    state: Optional[OperationState] = None,\n    /, *,\n    process_params: bool = True,\n    **extras\n):\n    if state and process_params:\n        # Case where parameters need processing\n\n        tile_sizes = []\n        for param, loop in zip(parameters, state.operation_features.nested_loops):\n            if param == 0:\n                tile_sizes.append(0)\n            else:\n                ts = 2 ** (param - 1)\n                assert loop.upper_bound % ts == 0 and loop.upper_bound != ts, \\\n                    f'Tiling parameter {param} is not a factor of loop upper bound {loop.upper_bound}'\n                tile_sizes.append(ts)\n        parameters = tile_sizes\n    super().__init__(parameters, state, **extras)\n</code></pre>"},{"location":"api_reference/actions/tiling/#mlir_rl_artifact.actions.tiling.Tiling.__get_tiles_count","title":"<code>__get_tiles_count(ub)</code>  <code>staticmethod</code>","text":"<p>Get the number of tiling candidates for a given loop upper bound.</p> <p>Parameters:</p> Name Type Description Default <code>ub</code> <code>int</code> <p>The loop upper bound.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of candidates.</p> Source code in <code>mlir_rl_artifact/actions/tiling.py</code> <pre><code>@staticmethod\ndef __get_tiles_count(ub: int) -&gt; int:\n    \"\"\"Get the number of tiling candidates for a given loop upper bound.\n\n    Args:\n        ub (int): The loop upper bound.\n\n    Returns:\n        int: The number of candidates.\n    \"\"\"\n    for i in range(Config().num_tile_sizes):\n        ts = 2 ** i\n        if ub % ts != 0 or ub == ts:\n            return i + 1\n    return Config().num_tile_sizes + 1\n</code></pre>"},{"location":"api_reference/actions/vectorization/","title":"Vectorization","text":"<p>Vectorization action for MLIR loop transformations.</p> <p>This module implements the vectorization transformation action, which applies vectorization to operations and handles preprocessing steps like transpose and decompose.</p>"},{"location":"api_reference/actions/vectorization/#mlir_rl_artifact.actions.vectorization.Vectorization","title":"<code>Vectorization(state=None, /, *, requires_transpose=None, requires_decompose=None, decompose_tile_sizes=None, **extras)</code>","text":"<p>               Bases: <code>Action</code></p> <p>Class representing Vectorization action</p> Source code in <code>mlir_rl_artifact/actions/vectorization.py</code> <pre><code>def __init__(\n    self,\n    state: Optional[OperationState] = None,\n    /, *,\n    requires_transpose: Optional[bool] = None,\n    requires_decompose: Optional[bool] = None,\n    decompose_tile_sizes: Optional[list[int]] = None,\n    **extras\n):\n    args_is_none = [\n        requires_transpose is None,\n        requires_decompose is None,\n        decompose_tile_sizes is None\n    ]\n    if (state is None) in args_is_none:\n        raise ValueError(\"Either state or preprocessing attributes must be provided and not both\")\n    if state:\n        op_feats = state.operation_features.copy()\n\n        if op_feats.operation_type not in [OperationType.Pooling, OperationType.Conv]:\n            requires_transpose, requires_decompose, decompose_tile_sizes = False, False, []\n        else:\n            if requires_transpose := self.__requires_transpose(op_feats):\n                op_feats.operation_name = 'linalg.conv_2d_nhwc_hwcf'\n            decompose_tile_sizes = []\n            if requires_decompose := self.__requires_decompose(op_feats):\n                decompose_tile_sizes = self.__decompose_tile_sizes(op_feats)\n    super().__init__(\n        state,\n        requires_transpose=requires_transpose,\n        requires_decompose=requires_decompose,\n        decompose_tile_sizes=decompose_tile_sizes,\n        vectorized=True,\n        **extras\n    )\n\n    self.preprocessing = []\n    if requires_transpose:\n        self.preprocessing.append(lambda m: transform_transpose_conv_2d(m, self.operation_tag))\n    if requires_decompose:\n        self.preprocessing.append(lambda m: transform_tile(m, self.operation_tag, decompose_tile_sizes))\n        self.preprocessing.append(lambda m: transform_decompose(m, self.operation_tag))\n    self.preprocessing.append(lambda m: transform_pre_vec(m, self.operation_tag))\n</code></pre>"},{"location":"api_reference/actions/vectorization/#mlir_rl_artifact.actions.vectorization.Vectorization.__requires_decompose","title":"<code>__requires_decompose(operation_features)</code>  <code>classmethod</code>","text":"<p>a.k.a is a two dimensional conv interface op</p> Source code in <code>mlir_rl_artifact/actions/vectorization.py</code> <pre><code>@classmethod\ndef __requires_decompose(cls, operation_features: OperationFeatures) -&gt; bool:\n    \"\"\"a.k.a is a two dimensional conv interface op\"\"\"\n\n    if 'conv_2d' in operation_features.operation_name:\n        return True\n\n    if operation_features.operation_type == OperationType.Pooling and len(operation_features.nested_loops) &gt;= 6:\n        return True\n\n    return False\n</code></pre>"},{"location":"api_reference/utils/bindings_process/","title":"Bindings Process","text":"<p>Process management for safe execution of MLIR bindings with timeouts.</p> <p>This module provides utilities for executing code in isolated processes to prevent crashes from unstable C++ bindings. It enables timeout management and proper resource cleanup for MLIR operations.</p>"},{"location":"api_reference/utils/config/","title":"Config","text":"<p>Global configuration management for MLIR RL training.</p> <p>This module provides a singleton configuration class that loads and validates configuration parameters from JSON files, managing all hyperparameters and settings for the training pipeline.</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config","title":"<code>Config()</code>","text":"<p>Class to store and load global configuration</p> Source code in <code>mlir_rl_artifact/utils/config.py</code> <pre><code>def __init__(self):\n    \"\"\"Load the configuration from the JSON file\n    or get existing instance if any.\n    \"\"\"\n    # Open the JSON file\n    with open(os.getenv(\"CONFIG_FILE_PATH\"), \"r\") as f:\n        config_data: dict[str, Any] = json.load(f)\n\n    for element, element_t in self.__annotations__.items():\n        if element not in config_data:\n            raise ValueError(f\"{element} is missing from the config file\")\n\n        element_v = check_type(config_data[element], element_t, collection_check_strategy=CollectionCheckStrategy.ALL_ITEMS)\n        setattr(self, element, element_v)\n</code></pre>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.bench_count","title":"<code>bench_count</code>  <code>instance-attribute</code>","text":"<p>Number of batches in a trajectory</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.benchmarks_folder_path","title":"<code>benchmarks_folder_path</code>  <code>instance-attribute</code>","text":"<p>Path to the benchmarks folder. Can be empty if optimization mode is set to \"last\".</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.debug","title":"<code>debug</code>  <code>instance-attribute</code>","text":"<p>Flag to enable debug mode</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.entropy_coef","title":"<code>entropy_coef</code>  <code>instance-attribute</code>","text":"<p>Entropy coefficient</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.eval_json_file","title":"<code>eval_json_file</code>  <code>instance-attribute</code>","text":"<p>Path to the JSON file containing the benchmarks execution times for evaluation.</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.exploration","title":"<code>exploration</code>  <code>instance-attribute</code>","text":"<p>The exploration method</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.init_epsilon","title":"<code>init_epsilon</code>  <code>instance-attribute</code>","text":"<p>The initial epsilon value for epsilon greedy exploration</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.interchange_mode","title":"<code>interchange_mode</code>  <code>instance-attribute</code>","text":"<p>The method used for interchange action</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.json_file","title":"<code>json_file</code>  <code>instance-attribute</code>","text":"<p>Path to the JSON file containing the benchmarks execution times.</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.lr","title":"<code>lr</code>  <code>instance-attribute</code>","text":"<p>Learning rate</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.main_exec_data_file","title":"<code>main_exec_data_file</code>  <code>instance-attribute</code>","text":"<p>Path to the file containing the execution data</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.max_num_load_store_dim","title":"<code>max_num_load_store_dim</code>  <code>instance-attribute</code>","text":"<p>The max number of dimensions in load/store buffers</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.max_num_loops","title":"<code>max_num_loops</code>  <code>instance-attribute</code>","text":"<p>The max number of nested loops</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.max_num_stores_loads","title":"<code>max_num_stores_loads</code>  <code>instance-attribute</code>","text":"<p>The maximum number of loads in the nested loops</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.nb_iterations","title":"<code>nb_iterations</code>  <code>instance-attribute</code>","text":"<p>Number of iterations</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.normalize_adv","title":"<code>normalize_adv</code>  <code>instance-attribute</code>","text":"<p>The advantage normalization method</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.normalize_bounds","title":"<code>normalize_bounds</code>  <code>instance-attribute</code>","text":"<p>Flag to indicate if the upper bounds in the input should be normalized or not</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.num_tile_sizes","title":"<code>num_tile_sizes</code>  <code>instance-attribute</code>","text":"<p>The number of tile sizes</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.order","title":"<code>order</code>  <code>instance-attribute</code>","text":"<p>The order of actions that needs to bo followed</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.ppo_batch_size","title":"<code>ppo_batch_size</code>  <code>instance-attribute</code>","text":"<p>Batch size for PPO</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.ppo_epochs","title":"<code>ppo_epochs</code>  <code>instance-attribute</code>","text":"<p>Number of epochs for PPO</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.replay_count","title":"<code>replay_count</code>  <code>instance-attribute</code>","text":"<p>Number of trajectories to keep in the replay buffer</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.results_dir","title":"<code>results_dir</code>  <code>instance-attribute</code>","text":"<p>Path to the results directory</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.reuse_experience","title":"<code>reuse_experience</code>  <code>instance-attribute</code>","text":"<p>Strategy for experience replay</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.tags","title":"<code>tags</code>  <code>instance-attribute</code>","text":"<p>List of tags to add to the neptune experiment</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.truncate","title":"<code>truncate</code>  <code>instance-attribute</code>","text":"<p>Maximum number of steps in the schedule</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.value_batch_size","title":"<code>value_batch_size</code>  <code>instance-attribute</code>","text":"<p>Batch size for value update</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.value_clip","title":"<code>value_clip</code>  <code>instance-attribute</code>","text":"<p>Clip value loss or not</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.value_coef","title":"<code>value_coef</code>  <code>instance-attribute</code>","text":"<p>Value coefficient</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.value_epochs","title":"<code>value_epochs</code>  <code>instance-attribute</code>","text":"<p>Number of epochs for value update</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.vect_size_limit","title":"<code>vect_size_limit</code>  <code>instance-attribute</code>","text":"<p>Vectorization size limit to prevent large sizes vectorization</p>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.__str__","title":"<code>__str__()</code>","text":"<p>Convert the configuration to a string.</p> Source code in <code>mlir_rl_artifact/utils/config.py</code> <pre><code>def __str__(self):\n    \"\"\"Convert the configuration to a string.\"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"api_reference/utils/config/#mlir_rl_artifact.utils.config.Config.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the configuration to a dictionary.</p> Source code in <code>mlir_rl_artifact/utils/config.py</code> <pre><code>def to_dict(self):\n    \"\"\"Convert the configuration to a dictionary.\"\"\"\n    return {k: self.__dict__[k] for k in self.__annotations__}\n</code></pre>"},{"location":"api_reference/utils/dask_manager/","title":"Dask Manager","text":"<p>Distributed computation management using Dask.</p> <p>This module handles distributed parallel execution of benchmark evaluations across multiple worker nodes. It provides abstractions for mapping functions across data in a distributed manner with resource management.</p>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager","title":"<code>DaskManager()</code>","text":"<p>DaskManager class for distributed parallel execution.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __init__(self):\n    if not ENABLED:\n        return\n\n    from dask_jobqueue import SLURMCluster\n    from distributed import Client\n\n    enable_dashboard = True\n    dask_reservation = os.getenv('DASK_RESERVATION')\n    dask_conda_env = os.getenv('CONDA_ENV')\n    cluster = SLURMCluster(\n        job_name='dask',\n        queue='compute',\n        cores=28,\n        processes=1,\n        nanny=True,\n        memory='100GB',\n        walltime='7-00',\n        job_extra_directives=[\n            f'--reservation={dask_reservation}' if dask_reservation else '',\n            '--nodes=1',\n            '--exclusive',\n        ],\n        worker_extra_args=['--resources', 'single_task_slot=1'],\n        log_directory='dask-logs',\n        job_script_prologue=[\n            'module load miniconda-nobashrc',\n            'eval \"$(conda shell.bash hook)\"',\n            f'conda activate {dask_conda_env}' if dask_conda_env else '',\n            'export OMP_NUM_THREADS=12',\n            'export DASK_DISTRIBUTED__WORKER__DAEMON=False' if BP_ENABLED else '',\n        ],\n        scheduler_options={\n            'dashboard': enable_dashboard,\n            'worker_ttl': '3600s'\n        }\n    )\n    self.cluster = cluster\n\n    num_nodes_to_use = int(os.environ[\"DASK_NODES\"])\n    print_info(f\"Requesting {num_nodes_to_use} nodes for Dask workers...\")\n    cluster.scale(jobs=num_nodes_to_use)\n    self.__keep_only_running()\n    print_success(f\"Got {self.num_workers} nodes\")\n\n    client = Client(cluster)\n    self.client = client\n    print_success(\"Dask client connected!\", f\"  Dashboard at: {client.dashboard_link}\" if enable_dashboard else \"\")\n\n    self.batch_timeout = 300\n    self.persistent_funcs: dict[str, Callable[[], Any]] = {}\n    self.persistent_futures: dict[str, 'Future'] = {}\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.num_workers","title":"<code>num_workers</code>  <code>property</code>","text":"<p>Number of available workers.</p>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.workers_names","title":"<code>workers_names</code>  <code>property</code>","text":"<p>List of available worker names.</p>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__get_persistent","title":"<code>__get_persistent(key, worker)</code>","text":"<p>Get the result of a persistent function from a worker.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the function.</p> required <code>worker</code> <code>str</code> <p>The worker to get the result from.</p> required <p>Returns:</p> Name Type Description <code>Future</code> <code>Future</code> <p>The future that points to the result of the function.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __get_persistent(self, key: str, worker: str) -&gt; 'Future':\n    \"\"\"Get the result of a persistent function from a worker.\n\n    Args:\n        key (str): The key of the function.\n        worker (str): The worker to get the result from.\n\n    Returns:\n        Future: The future that points to the result of the function.\n    \"\"\"\n\n    worker_key = f'{key}_{worker}'\n    if worker_key in self.persistent_futures:\n        return self.persistent_futures[worker_key]\n\n    print_alert(f\"Future {key} not found in worker {worker}, attemtping recomputation!\")\n    if key in self.persistent_funcs:\n        return self.__submit_persistent(key, worker)\n\n    raise Exception(f\"Unable to find or compute future {key}\")\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__keep_only_running","title":"<code>__keep_only_running()</code>","text":"<p>Keep only workers with running jobs</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __keep_only_running(self):\n    \"\"\"Keep only workers with running jobs\"\"\"\n    if TYPE_CHECKING:\n        from dask_jobqueue.slurm import SLURMJob\n\n    # Wait for the cluster to submit the jobs\n    async def _():\n        await self.cluster\n    self.cluster.sync(_)\n\n    # Get workers and their job ids\n    workers: dict[str, 'SLURMJob'] = self.cluster.workers\n    if not workers:\n        return\n    job_id_to_worker = {j.job_id: w for w, j in workers.items() if isinstance(j.job_id, str)}\n\n    # Give it some time for the jobs to be accepted\n    pending_jobs = set(job_id_to_worker.keys())\n    start_wait = time()\n    print_info(\"Waiting for jobs to be accepted\")\n    while time() - start_wait &lt; 60 and pending_jobs:\n        command = ['squeue', '-h', '-o', '%i %T', '-j', ','.join(job_id_to_worker.keys())]\n        running_workers: set[str] = set()\n        pending_jobs: set[str] = set()\n        try:\n            # Run the command\n            result = subprocess.run(command, capture_output=True, text=True, check=True)\n\n            # The output will be one status per line\n            output_statuses = result.stdout.strip().split('\\n')\n\n            # Map job IDs to their retrieved statuses\n            for id_status in output_statuses:\n                job_id, status = id_status.split()\n                if status == 'RUNNING':\n                    running_workers.add(job_id_to_worker[job_id])\n                elif status == 'PENDING':\n                    pending_jobs.add(job_id_to_worker[job_id])\n        except subprocess.CalledProcessError:\n            pass\n        sleep(1)\n    non_running_workers = set(workers.keys()) - running_workers\n    if non_running_workers:\n        print_alert(\n            f\"Jobs weren't accepted for workers: {non_running_workers}\\n\"\n            \"Removing those workers from cluster\"\n        )\n        self.cluster.sync(self.cluster.scale_down, non_running_workers)\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__renew_persistent","title":"<code>__renew_persistent(key, worker)</code>","text":"<p>Recompute the result of a persistent function on a worker. This should be called when a persistent result (Future) has become invalid (due to a worker failure mostly).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the function.</p> required <code>worker</code> <code>str</code> <p>The worker to renew the result on.</p> required <p>Returns:</p> Name Type Description <code>Future</code> <code>Future</code> <p>The future that points to the result of the function.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __renew_persistent(self, key: str, worker: str) -&gt; 'Future':\n    \"\"\"Recompute the result of a persistent function on a worker.\n    This should be called when a persistent result (Future) has\n    become invalid (due to a worker failure mostly).\n\n    Args:\n        key (str): The key of the function.\n        worker (str): The worker to renew the result on.\n\n    Returns:\n        Future: The future that points to the result of the function.\n    \"\"\"\n    worker_key = f'{key}_{worker}'\n    if worker_key in self.persistent_futures:\n        del self.persistent_futures[worker_key]\n\n    return self.__submit_persistent(key, worker)\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__renew_worker_persistents","title":"<code>__renew_worker_persistents(worker)</code>","text":"<p>Recompute all persistent functions on a worker. This should be called when a worker has failed.</p> <p>Parameters:</p> Name Type Description Default <code>worker</code> <code>str</code> <p>The worker to renew the results on.</p> required Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __renew_worker_persistents(self, worker: str):\n    \"\"\"Recompute all persistent functions on a worker.\n    This should be called when a worker has failed.\n\n    Args:\n        worker (str): The worker to renew the results on.\n    \"\"\"\n    for key in self.persistent_funcs:\n        self.__renew_persistent(key, worker)\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__submit_obj","title":"<code>__submit_obj(func, idx, obj, worker, training)</code>","text":"<p>Execute a function on an object, and submit it to a worker.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[obj_T, str, Benchmarks, Optional[dict[str, dict[str, int]]]], T]</code> <p>The function to execute.</p> required <code>idx</code> <code>int</code> <p>The index of the object (for tracking purposes).</p> required <code>obj</code> <code>obj_T</code> <p>The object to execute the function on.</p> required <code>worker</code> <code>str</code> <p>The worker to submit the result to.</p> required <code>training</code> <code>bool</code> <p>Whether the object is for training. if True, the function will be executed with a timeout and the training benchmarks will be used instead of evaluation.</p> required <p>Returns:</p> Name Type Description <code>Future</code> <code>Future</code> <p>The future that points to the result of the function.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __submit_obj(\n    self,\n    func: Callable[[obj_T, str, 'Benchmarks', Optional[dict[str, dict[str, int]]]], T],\n    idx: int,\n    obj: obj_T,\n    worker: str,\n    training: bool\n) -&gt; 'Future':\n    \"\"\"Execute a function on an object, and submit it to a worker.\n\n    Args:\n        func (Callable[[obj_T, str, 'Benchmarks', Optional[dict[str, dict[str, int]]]], T]): The function to execute.\n        idx (int): The index of the object (for tracking purposes).\n        obj (obj_T): The object to execute the function on.\n        worker (str): The worker to submit the result to.\n        training (bool): Whether the object is for training. if True,\n            the function will be executed with a timeout and the\n            training benchmarks will be used instead of evaluation.\n\n    Returns:\n        Future: The future that points to the result of the function.\n    \"\"\"\n    # Add a wrapper to track state order\n    def func_wrapper(idx: int, *args):\n        return idx, func(*args)\n    func_wrapper.__name__ = func.__name__ + '_wrapper'\n\n    exec_data_file = FileLogger().exec_data_file\n    benchs = self.__get_persistent('load_train_data' if training else 'load_eval_data', worker)\n    main_exec_data = self.__get_persistent('load_main_exec_data', worker)\n\n    return self.client.submit(\n        func_wrapper,\n        idx, obj, exec_data_file, benchs, main_exec_data,\n        workers=worker,\n        resources={'single_task_slot': 1},\n        pure=False\n    )\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.__submit_persistent","title":"<code>__submit_persistent(key, worker)</code>","text":"<p>Submit a persistent function to a worker, and keep track of its result (Future) for re-use.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the function.</p> required <code>worker</code> <code>str</code> <p>The worker to submit the function to.</p> required <p>Returns:</p> Name Type Description <code>Future</code> <code>Future</code> <p>The future of the function.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def __submit_persistent(self, key: str, worker: str) -&gt; 'Future':\n    \"\"\"Submit a persistent function to a worker,\n    and keep track of its result (Future) for re-use.\n\n    Args:\n        key (str): The key of the function.\n        worker (str): The worker to submit the function to.\n\n    Returns:\n        Future: The future of the function.\n    \"\"\"\n    assert key in self.persistent_funcs, f\"Task {key} expected to be registered\"\n    func = self.persistent_funcs[key]\n\n    worker_key = f'{key}_{worker}'\n    assert worker_key not in self.persistent_futures, f\"Future {key} was found existing in worker {worker}\"\n\n    future = self.client.submit(\n        func,\n        workers=worker,\n        pure=False\n    )\n    self.persistent_futures[worker_key] = future\n\n    return future\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.close","title":"<code>close()</code>","text":"<p>Close the cluster and client.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def close(self):\n    \"\"\"Close the cluster and client.\"\"\"\n    self.client.close()\n    self.cluster.close()\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.map_objs","title":"<code>map_objs(func, objs, benchs, main_exec_data, training, obj_str=lambda o: str(o))</code>","text":"<p>Map a function across objects in a distributed manner.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[obj_T, str, Benchmarks, Optional[dict[str, dict[str, int]]]], T]</code> <p>The function to apply to each object.</p> required <code>objs</code> <code>Iterable[obj_T]</code> <p>The objects to apply the function to.</p> required <code>benchs</code> <code>Benchmarks</code> <p>The benchmark suite to use.</p> required <code>main_exec_data</code> <code>Optional[dict[str, dict[str, int]]]</code> <p>The main execution data (if available).</p> required <code>training</code> <code>bool</code> <p>Whether the mapping is for training. if True, the function will be executed with a timeout and the training benchmarks will be used instead of evaluation.</p> required <code>obj_str</code> <code>Callable[[obj_T], str]</code> <p>A function to convert each object to a string for logging.</p> <code>lambda o: str(o)</code> <p>Returns:</p> Type Description <code>list[Optional[T]]</code> <p>list[Optional[T]]: A list of the results of the function applied to each object.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def map_objs(\n    self,\n    func: Callable[[obj_T, str, 'Benchmarks', Optional[dict[str, dict[str, int]]]], T],\n    objs: Iterable[obj_T],\n    benchs: 'Benchmarks',\n    main_exec_data: Optional[dict[str, dict[str, int]]],\n    training: bool,\n    obj_str: Callable[[obj_T], str] = lambda o: str(o)\n) -&gt; list[Optional[T]]:\n    \"\"\"Map a function across objects in a distributed manner.\n\n    Args:\n        func (Callable[[obj_T, str, 'Benchmarks', Optional[dict[str, dict[str, int]]]], T]):\n            The function to apply to each object.\n        objs (Iterable[obj_T]): The objects to apply the function to.\n        benchs (Benchmarks): The benchmark suite to use.\n        main_exec_data (Optional[dict[str, dict[str, int]]]): The main execution data (if available).\n        training (bool): Whether the mapping is for training. if True,\n            the function will be executed with a timeout and the\n            training benchmarks will be used instead of evaluation.\n        obj_str (Callable[[obj_T], str]): A function to convert each object to a string for logging.\n\n    Returns:\n        list[Optional[T]]: A list of the results of the function applied to each object.\n    \"\"\"\n\n    if not ENABLED or self.num_workers == 0:\n        return [func(o, FileLogger().exec_data_file, benchs, main_exec_data) for o in objs]\n\n    from distributed import as_completed\n\n    # Prepare objs for submission\n    objs_count = len(objs)\n    ordered_objs = list(zip(range(objs_count), objs))\n    results: list[Optional[T]] = [None] * objs_count\n    future_to_worker: dict['Future', str] = {}\n\n    # Submit first objs to each worker\n    initial_objs_count = min(objs_count, self.num_workers)\n    for i in range(initial_objs_count):\n        worker_name = self.workers_names[i]\n        future = self.__submit_obj(func, *ordered_objs.pop(0), worker_name, training)\n        future_to_worker[future] = worker_name\n\n    # Process futures as they finish\n    ac = as_completed(future_to_worker.keys(), with_results=True, timeout=self.batch_timeout if training else None)\n    try:\n        for future, indexed_result in ac:\n            future: 'Future'\n            indexed_result: tuple[int, T]\n\n            idx, result = indexed_result\n            results[idx] = result\n            freed_worker = future_to_worker.pop(future)\n\n            # If there are still remaining objs submit them\n            if ordered_objs:\n                new_future = self.__submit_obj(func, *ordered_objs.pop(0), freed_worker, training)\n                future_to_worker[new_future] = freed_worker\n\n                # Include the new future in the queue\n                ac.add(new_future)\n\n    except TimeoutError:\n        self.client.cancel(list(future_to_worker.keys()), reason='task-timeout', msg='Task timed out', force=True)\n        failed_workers = list(future_to_worker.values())\n        try:\n            self.client.restart_workers(failed_workers, raise_for_error=False)\n        except Exception:\n            pass\n        restarted_workers = set(failed_workers).intersection(set(self.workers_names))\n        unrestarted_workers = set(failed_workers) - set(self.workers_names)\n        for worker in restarted_workers:\n            self.__renew_worker_persistents(worker)\n        print_error(\n            \"States exec timed out\\n\"\n            f\"Cancelling benchmarks: {[obj_str(o) for o, r in zip(objs, results) if r is None]}\\n\"\n            f\"Unvisited benchmarks: {[obj_str(o) for _, o in ordered_objs]}\\n\"\n            f\"Restarted workers: {restarted_workers}\\n\"\n            f\"Failed to restart workers: {unrestarted_workers}\"\n        )\n\n    return results\n</code></pre>"},{"location":"api_reference/utils/dask_manager/#mlir_rl_artifact.utils.dask_manager.DaskManager.run_and_register_to_workers","title":"<code>run_and_register_to_workers(func)</code>","text":"<p>Run a function both locally and on the workers. The result will be registered to all workers, and returned by this function.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[], T]</code> <p>The function to run.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>The result of the function.</p> Source code in <code>mlir_rl_artifact/utils/dask_manager.py</code> <pre><code>def run_and_register_to_workers(self, func: Callable[[], T]) -&gt; T:\n    \"\"\"Run a function both locally and on the workers.\n    The result will be registered to all workers, and\n    returned by this function.\n\n    Args:\n        func (Callable[[], T]): The function to run.\n\n    Returns:\n        T: The result of the function.\n    \"\"\"\n\n    if not ENABLED or self.num_workers == 0:\n        return func()\n\n    key = func.__name__\n    if key in self.persistent_funcs:\n        return func()\n    self.persistent_funcs[key] = func\n\n    for worker in self.workers_names:\n        self.__submit_persistent(key, worker)\n\n    return func()\n</code></pre>"},{"location":"api_reference/utils/file_logger/","title":"File Logger","text":"<p>Result logging and file management for training metrics.</p> <p>This module provides file-based logging for training metrics, model artifacts, and execution results. It manages result directories and enables time-series metric tracking throughout training.</p>"},{"location":"api_reference/utils/file_logger/#mlir_rl_artifact.utils.file_logger.FileLogger","title":"<code>FileLogger()</code>","text":"<p>Class to log results to files</p> Source code in <code>mlir_rl_artifact/utils/file_logger.py</code> <pre><code>def __init__(self):\n    self.enabled = True\n    cfg = Config()\n\n    # Create run dir\n    dir_path = cfg.results_dir\n    subdir_ids = sorted([int(d.split('_')[-1]) for d in os.listdir(dir_path) if d.startswith('run_')])\n    run_id = subdir_ids[-1] + 1 if subdir_ids else 0\n    self.run_dir = os.path.join(dir_path, f'run_{run_id}')\n    os.makedirs(self.run_dir, exist_ok=True)\n\n    # Create tags file\n    tags_file = os.path.join(self.run_dir, 'tags')\n    with open(tags_file, 'w') as f:\n        f.write('\\n'.join(cfg.tags))\n        f.write('\\n')\n\n    # Create exec data file\n    self.exec_data_file = os.path.join(self.run_dir, 'exec_data.json')\n    with open(self.exec_data_file, \"w\") as f:\n        json.dump({}, f)\n\n    # Create logs dir\n    self.logs_dir = os.path.join(self.run_dir, 'logs')\n    os.makedirs(self.logs_dir, exist_ok=True)\n\n    # Create models dir\n    self.models_dir = os.path.join(self.run_dir, 'models')\n    os.makedirs(self.models_dir, exist_ok=True)\n\n    # Init files dict\n    self.files_dict: dict[str, FileInstance] = {}\n</code></pre>"},{"location":"api_reference/utils/gpu_occupier/","title":"GPU Occupier","text":"<p>GPU resource management and memory occupancy utilities.</p> <p>This module provides utilities for managing GPU resources during training, including methods to reserve GPU memory and ensure consistent GPU availability for model training.</p>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier","title":"<code>GPUOccupier()</code>","text":"<p>Manages a parallel process to keep the GPU busy when it is idle.</p> Source code in <code>mlir_rl_artifact/utils/gpu_occupier.py</code> <pre><code>def __init__(self):\n    self.__ctx = multiprocessing.get_context('spawn')\n    self.__gpu_needed_event = self.__ctx.Event()\n    self.__stop_event = self.__ctx.Event()\n    self.__process = None\n</code></pre>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier.__ctx","title":"<code>__ctx = multiprocessing.get_context('spawn')</code>  <code>instance-attribute</code>","text":"<p>Multiprocessing context.</p>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier.__gpu_needed_event","title":"<code>__gpu_needed_event = self.__ctx.Event()</code>  <code>instance-attribute</code>","text":"<p>Event that is set when the GPU is needed.</p>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier.__process","title":"<code>__process = None</code>  <code>instance-attribute</code>","text":"<p>Process that keeps the GPU busy.</p>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier.__stop_event","title":"<code>__stop_event = self.__ctx.Event()</code>  <code>instance-attribute</code>","text":"<p>Event that is set when the process should stop.</p>"},{"location":"api_reference/utils/gpu_occupier/#mlir_rl_artifact.utils.gpu_occupier.GPUOccupier.gpu_needed","title":"<code>gpu_needed()</code>","text":"<p>Context manager that signals that the GPU is needed.</p> Source code in <code>mlir_rl_artifact/utils/gpu_occupier.py</code> <pre><code>@contextmanager\ndef gpu_needed(self):\n    \"\"\"Context manager that signals that the GPU is needed.\"\"\"\n\n    if self.__gpu_needed_event.is_set():\n        yield\n        return\n    self.__gpu_needed_event.set()\n    try:\n        yield\n    finally:\n        self.__gpu_needed_event.clear()\n</code></pre>"},{"location":"api_reference/utils/log/","title":"Log","text":"<p>Logging utilities for console output with labels and colors.</p> <p>This module provides helper functions for printing status messages with labels and consistent formatting, supporting both local and distributed execution.</p>"},{"location":"api_reference/utils/log/#mlir_rl_artifact.utils.log.generate_random_string","title":"<code>generate_random_string()</code>","text":"<p>Generate a random string of length 10</p> Source code in <code>mlir_rl_artifact/utils/log.py</code> <pre><code>def generate_random_string():\n    \"\"\"Generate a random string of length 10\"\"\"\n    return ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n</code></pre>"},{"location":"api_reference/utils/log/#mlir_rl_artifact.utils.log.print_alert","title":"<code>print_alert(*args, add_label=True, **kwargs)</code>","text":"<p>Prints an alert message</p> Source code in <code>mlir_rl_artifact/utils/log.py</code> <pre><code>def print_alert(*args, add_label: bool = True, **kwargs):\n    \"\"\"Prints an alert message\"\"\"\n    message = ' '.join(map(str, args))\n    label = f'{time_log()} - [ALERT]    ' if add_label else ''\n    for line in message.split('\\n'):\n        print(f\"\\033[93m{label}{line}\\033[0m\", file=sys.stderr, **kwargs)\n</code></pre>"},{"location":"api_reference/utils/log/#mlir_rl_artifact.utils.log.print_error","title":"<code>print_error(*args, add_label=True, with_barrier=True, **kwargs)</code>","text":"<p>Prints an error message</p> Source code in <code>mlir_rl_artifact/utils/log.py</code> <pre><code>def print_error(*args, add_label: bool = True, with_barrier: bool = True, **kwargs):\n    \"\"\"Prints an error message\"\"\"\n    message = ' '.join(map(str, args))\n    if with_barrier:\n        message = '\\n----------------------------------------\\n' + message + '\\n----------------------------------------\\n'\n    label = f'{time_log()} - [ERROR]    ' if add_label else ''\n    for line in message.split('\\n'):\n        print(f\"\\033[91m{label}{line}\\033[0m\", file=sys.stderr, **kwargs)\n</code></pre>"},{"location":"api_reference/utils/log/#mlir_rl_artifact.utils.log.print_info","title":"<code>print_info(*args, add_label=True, **kwargs)</code>","text":"<p>Prints an information message</p> Source code in <code>mlir_rl_artifact/utils/log.py</code> <pre><code>def print_info(*args, add_label: bool = True, **kwargs):\n    \"\"\"Prints an information message\"\"\"\n    message = ' '.join(map(str, args))\n    label = f'{time_log()} - [INFO]    ' if add_label else ''\n    for line in message.split('\\n'):\n        print(f\"\\033[94m{label}{line}\\033[0m\", **kwargs)\n</code></pre>"},{"location":"api_reference/utils/log/#mlir_rl_artifact.utils.log.print_success","title":"<code>print_success(*args, add_label=True, **kwargs)</code>","text":"<p>Prints a success message</p> Source code in <code>mlir_rl_artifact/utils/log.py</code> <pre><code>def print_success(*args, add_label: bool = True, **kwargs):\n    \"\"\"Prints a success message\"\"\"\n    message = ' '.join(map(str, args))\n    label = f'{time_log()} - [SUCCESS]    ' if add_label else ''\n    for line in message.split('\\n'):\n        print(f\"\\033[92m{label}{line}\\033[0m\", **kwargs)\n</code></pre>"},{"location":"api_reference/utils/singleton/","title":"Singleton","text":"<p>Singleton metaclass for ensuring single instance of classes.</p> <p>This module provides a metaclass that enforces the singleton pattern, ensuring only one instance of a class is created throughout the application lifetime.</p>"},{"location":"api_reference/utils/singleton/#mlir_rl_artifact.utils.singleton.Singleton","title":"<code>Singleton</code>","text":"<p>               Bases: <code>type</code></p> <p>Meta class to create a singleton instance of a class</p>"},{"location":"entry_points/evaluate/","title":"Evaluation Script","text":"<p>Evaluation script for trained MLIR RL models.</p> <p>This module evaluates all trained model checkpoints on benchmark datasets, measuring optimization quality through speedup factors and execution times.</p>"},{"location":"entry_points/evaluate/#evaluate.main","title":"<code>main()</code>","text":"<p>Execute evaluation of all trained models on benchmark datasets.</p> <p>Loads all model checkpoints from the models directory, evaluates each on the benchmark dataset in greedy mode, and logs results.</p> Source code in <code>evaluate.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Execute evaluation of all trained models on benchmark datasets.\n\n    Loads all model checkpoints from the models directory, evaluates each on the\n    benchmark dataset in greedy mode, and logs results.\n    \"\"\"\n    torch.manual_seed(123)\n    torch.cuda.manual_seed_all(123)\n    np.random.seed(123)\n    random.seed(123)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n    # Initialize singleton classes\n    cfg = Config()\n    fl = FileLogger()\n    dm = DaskManager()\n    go = GPUOccupier()\n\n    # Start GPU Occupier\n    if device.type == \"cuda\":\n        go.start(device)\n\n    # Data loading\n    def load_eval_data():\n        return Benchmarks(is_training=False)\n\n    def load_main_exec_data() -&gt; Optional[dict[str, dict[str, int]]]:\n        return None\n\n    eval_data = dm.run_and_register_to_workers(load_eval_data)\n    main_exec_data = dm.run_and_register_to_workers(load_main_exec_data)\n\n    # Initialize execution singleton\n    Execution(fl.exec_data_file, main_exec_data)\n\n    # Prepare logging\n    print_success(f'Logging to: {fl.run_dir}')\n\n    # Setup torch\n    torch.set_grad_enabled(False)\n    torch.set_num_threads(4)\n\n    # Initiate model\n    with go.gpu_needed():\n        model = Model().to(device)\n    print_success(\"Model initialized\")\n\n    # Read the files in the evaluation directory\n    eval_files = [f for f in os.listdir(eval_dir) if re.match(r'model_\\d+\\.(pt|pth)', f)]\n\n    # Order files\n    eval_files.sort(key=lambda x: int(re.match(r'model_(\\d+)\\.(pt|pth)', x).group(1)))\n\n    iter_time_dlt = 0\n    elapsed_dlt = 0\n    eta_dlt = 0\n    overall_start = time()\n    models_count = len(eval_files)\n    for step, model_file in enumerate(eval_files):\n        print_info(\n            f\"- Evaluation {model_file}\"\n            f\" ({100 * (step + 1) / models_count:.2f}%)\"\n            f\" ({iter_time_dlt}/it) ({elapsed_dlt} &lt; {eta_dlt})\",\n            flush=True\n        )\n\n        main_start = time()\n\n        model_path = os.path.join(eval_dir, model_file)\n        if not os.path.exists(model_path):\n            print_info(f\"Model file {model_path} does not exist. Skipping.\")\n            continue\n        with go.gpu_needed():\n            model.load_state_dict(torch.load(model_path, weights_only=True))\n\n        evaluate_benchmarks(model, eval_data)\n\n        main_end = time()\n        iter_time = main_end - main_start\n        elapsed = main_end - overall_start\n        eta = elapsed * (cfg.nb_iterations - step - 1) / (step + 1)\n        iter_time_dlt = timedelta(seconds=iter_time)\n        elapsed_dlt = timedelta(seconds=int(elapsed))\n        eta_dlt = timedelta(seconds=int(eta))\n</code></pre>"},{"location":"entry_points/train/","title":"Training Script","text":"<p>Main training script for MLIR RL using PPO.</p> <p>This module implements the primary training loop for the reinforcement learning system. It initializes the models, loads benchmark data, and iterates through PPO training steps including trajectory collection, policy updates, and periodic evaluation.</p>"},{"location":"entry_points/train/#train.main","title":"<code>main()</code>","text":"<p>Execute the main training loop for MLIR RL.</p> <p>Initializes the training infrastructure, loads benchmark data, and runs PPO training for the specified number of iterations. Includes periodic model saving and benchmark evaluation.</p> Source code in <code>train.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Execute the main training loop for MLIR RL.\n\n    Initializes the training infrastructure, loads benchmark data, and runs PPO\n    training for the specified number of iterations. Includes periodic model saving\n    and benchmark evaluation.\n    \"\"\"\n    torch.manual_seed(123)\n    torch.cuda.manual_seed_all(123)\n    np.random.seed(123)\n    random.seed(123)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n    # Initialize singleton classes\n    cfg = Config()\n    fl = FileLogger()\n    dm = DaskManager()\n    go = GPUOccupier()\n\n    # Start GPU Occupier\n    if device.type == \"cuda\":\n        go.start(device)\n\n    # Data loading\n    def load_train_data():\n        return Benchmarks()\n\n    def load_eval_data():\n        return Benchmarks(is_training=False)\n\n    def load_main_exec_data() -&gt; Optional[dict[str, dict[str, int]]]:\n        main_exec_data = None\n        if Config().main_exec_data_file:\n            with open(Config().main_exec_data_file) as f:\n                main_exec_data = json.load(f)\n        return main_exec_data\n\n    train_data = dm.run_and_register_to_workers(load_train_data)\n    eval_data = dm.run_and_register_to_workers(load_eval_data)\n    main_exec_data = dm.run_and_register_to_workers(load_main_exec_data)\n\n    # Initialize execution singleton\n    Execution(fl.exec_data_file, main_exec_data)\n\n    print_success(f'Logging to: {fl.run_dir}')\n    if cfg.main_exec_data_file:\n        print_info(f\"Global execution data located in: {cfg.main_exec_data_file}\")\n\n    # Setup torch\n    torch.set_grad_enabled(False)\n    torch.set_num_threads(4)\n    if cfg.debug:\n        torch.autograd.set_detect_anomaly(True)\n\n    # Initiate model\n    with go.gpu_needed():\n        model = Model().to(device)\n    optimizer = torch.optim.Adam(\n        model.parameters(),\n        lr=cfg.lr\n    )\n    print_success(\"Model initialized\")\n\n    # Start training\n    old_trajectory: Optional[TrajectoryData] = None\n    iter_time_dlt = 0\n    elapsed_dlt = 0\n    eta_dlt = 0\n    overall_start = time()\n    for step in range(cfg.nb_iterations):\n        print_info(\n            f\"- Main Loop {step + 1}/{cfg.nb_iterations}\"\n            f\" ({100 * (step + 1) / cfg.nb_iterations:.2f}%)\"\n            f\" ({iter_time_dlt}/it) ({elapsed_dlt} &lt; {eta_dlt})\",\n            flush=True\n        )\n\n        main_start = time()\n\n        # Collect trajectory using the model\n        trajectory = collect_trajectory(train_data, model, step)\n\n        # Extend trajectory with previous trajectory\n        if cfg.reuse_experience != 'none':\n            reuse_start = time()\n            if old_trajectory is not None:\n                trajectory = old_trajectory + trajectory\n            old_trajectory = trajectory.copy()\n            reuse_end = time()\n            reuse_time_ms = int((reuse_end - reuse_start) * 1000)\n            print_info(f\"Reuse time: {reuse_time_ms}ms\")\n\n        # Fit value model to trajectory rewards\n        if cfg.value_epochs &gt; 0:\n            with go.gpu_needed():\n                value_update(trajectory, model, optimizer)\n\n        # Update policy model with PPO\n        with go.gpu_needed():\n            ppo_update(trajectory, model, optimizer)\n\n        # Save the model\n        if (step + 1) % 5 == 0:\n            torch.save(\n                model.state_dict(),\n                os.path.join(\n                    fl.models_dir,\n                    f'model_{step}.pt'\n                )\n            )\n\n        if (step + 1) % 100 == 0:\n            print_info('- Evaluating benchmarks -')\n            evaluate_benchmarks(model, eval_data)\n\n        main_end = time()\n        iter_time = main_end - main_start\n        elapsed = main_end - overall_start\n        eta = elapsed * (cfg.nb_iterations - step - 1) / (step + 1)\n        iter_time_dlt = timedelta(seconds=iter_time)\n        elapsed_dlt = timedelta(seconds=int(elapsed))\n        eta_dlt = timedelta(seconds=int(eta))\n\n    if (step + 1) % 100 != 0:\n        print_info('- Evaluating benchmarks -')\n        evaluate_benchmarks(model, eval_data)\n\n    dm.close()\n    go.stop()\n</code></pre>"}]}